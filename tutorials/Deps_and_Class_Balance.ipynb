{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1353238a70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF Dependencies: [(0, 1)]\n",
      "Class Balance: [0.50537711 0.49462289]\n"
     ]
    }
   ],
   "source": [
    "from synthetic.generate import SingleTaskTreeDepsGenerator\n",
    "\n",
    "K = 2\n",
    "M = 10\n",
    "N = 10000\n",
    "\n",
    "# Generate the true class balance to be recovered\n",
    "class_balance = np.ones(K)/K + np.random.random(K)/5.\n",
    "class_balance /= class_balance.sum()\n",
    "\n",
    "data = SingleTaskTreeDepsGenerator(N, M, K, class_balance, edges=[(0,1)])\n",
    "print (f\"LF Dependencies: {data.E}\")\n",
    "print (f\"Class Balance: {data.p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.7254</td>\n",
       "      <td>7277</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.845180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.7636</td>\n",
       "      <td>8136</td>\n",
       "      <td>955</td>\n",
       "      <td>0.894951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>7009</td>\n",
       "      <td>1513</td>\n",
       "      <td>0.822460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.7493</td>\n",
       "      <td>0.7493</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>5010</td>\n",
       "      <td>2483</td>\n",
       "      <td>0.668624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.6224</td>\n",
       "      <td>4598</td>\n",
       "      <td>2661</td>\n",
       "      <td>0.633421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>7427</td>\n",
       "      <td>1298</td>\n",
       "      <td>0.851232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>7864</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.880036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>5861</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.743971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>6567</td>\n",
       "      <td>1667</td>\n",
       "      <td>0.797547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.8248</td>\n",
       "      <td>0.8248</td>\n",
       "      <td>0.6976</td>\n",
       "      <td>6465</td>\n",
       "      <td>1783</td>\n",
       "      <td>0.783826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
       "0   [1, 2]    0.8610    0.8610     0.7254     7277       1333   0.845180\n",
       "1   [1, 2]    0.9091    0.9091     0.7636     8136        955   0.894951\n",
       "2   [1, 2]    0.8522    0.8522     0.7199     7009       1513   0.822460\n",
       "3   [1, 2]    0.7493    0.7493     0.6409     5010       2483   0.668624\n",
       "4   [1, 2]    0.7259    0.7259     0.6224     4598       2661   0.633421\n",
       "5   [1, 2]    0.8725    0.8725     0.7301     7427       1298   0.851232\n",
       "6   [1, 2]    0.8936    0.8936     0.7495     7864       1072   0.880036\n",
       "7   [1, 2]    0.7878    0.7878     0.6674     5861       2017   0.743971\n",
       "8   [1, 2]    0.8234    0.8234     0.6908     6567       1667   0.797547\n",
       "9   [1, 2]    0.8248    0.8248     0.6976     6465       1783   0.783826"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal.analysis import lf_summary\n",
    "lf_summary(data.L,data.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Learn Dependencies using `DependencyLearnerModel`\n",
    "**TEMP: hardcoding for now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = data.E\n",
    "L = np.array(data.L.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Recover the class balance using subset of independent LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate indices for independent LFs\n",
    "ind_lfs = []\n",
    "for i in range(M):\n",
    "    if i not in list(sum(edges, ())):\n",
    "        ind_lfs.append(i)\n",
    "L_ind = L[:,ind_lfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated class balance: [0.50483036 0.49531323]\n",
      "True class balance: [0.50537711 0.49462289]\n",
      "\n",
      "CPU times: user 3.28 s, sys: 152 ms, total: 3.43 s\n",
      "Wall time: 922 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from metal.label_model.class_balance import ClassBalanceModel\n",
    "\n",
    "cb_model = ClassBalanceModel(K, abstains=True)\n",
    "cb_model.train_model(L=L_ind, verbose=False)\n",
    "\n",
    "print(f\"Estimated class balance: {cb_model.class_balance}\")\n",
    "print(f\"True class balance: {class_balance}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train `LabelModel` using $\\mu$ from `ClassBalanceModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O^{-1}...\n",
      "Estimating Z...\n",
      "[100 epo]: TRAIN:[loss=8.079]\n",
      "[200 epo]: TRAIN:[loss=8.028]\n",
      "[300 epo]: TRAIN:[loss=8.028]\n",
      "[400 epo]: TRAIN:[loss=8.028]\n",
      "[500 epo]: TRAIN:[loss=8.028]\n",
      "[600 epo]: TRAIN:[loss=8.028]\n",
      "[700 epo]: TRAIN:[loss=8.028]\n",
      "[800 epo]: TRAIN:[loss=8.028]\n",
      "[900 epo]: TRAIN:[loss=8.028]\n",
      "[1000 epo]: TRAIN:[loss=8.028]\n",
      "Finished Training\n",
      "Estimating \\mu...\n",
      "[100 epo]: TRAIN:[loss=0.067]\n",
      "[200 epo]: TRAIN:[loss=0.037]\n",
      "[300 epo]: TRAIN:[loss=0.021]\n",
      "[400 epo]: TRAIN:[loss=0.012]\n",
      "[500 epo]: TRAIN:[loss=0.007]\n",
      "[600 epo]: TRAIN:[loss=0.004]\n",
      "[700 epo]: TRAIN:[loss=0.002]\n",
      "[800 epo]: TRAIN:[loss=0.001]\n",
      "[900 epo]: TRAIN:[loss=0.001]\n",
      "[1000 epo]: TRAIN:[loss=0.000]\n",
      "Finished Training\n",
      "\n",
      "Error between mu and cond_probs for y = 1: 0.0028541550040245057\n",
      "Error between mu and cond_probs for y = 2: 0.003642233833670616\n",
      "\n",
      "CPU times: user 22.1 s, sys: 2.64 s, total: 24.7 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from metal.label_model import LabelModel\n",
    "label_model = LabelModel(verbose=True,k=K, seed=123)\n",
    "\n",
    "label_model.train_model(\n",
    "    data.L, \n",
    "    cond_probs = cb_model.cond_probs, \n",
    "    ind_lfs = ind_lfs, \n",
    "    deps = edges, \n",
    "    lr = 1e-3, \n",
    "    n_epochs = 1000, \n",
    "    log_train_every = 100\n",
    ")\n",
    "\n",
    "print()\n",
    "for y in range(K):\n",
    "    mu_idx = [il*K + y for il in ind_lfs]\n",
    "    err = np.linalg.norm(label_model.mu[mu_idx,:].detach().numpy() - \n",
    "                         cb_model.cond_probs[:,y+1,:])/(M*1.0)\n",
    "    print(f\"Error between mu and cond_probs for y = {y+1}: {err}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Label Model Metrics:\n",
      "Accuracy: 0.974\n",
      "Precision: 0.972\n",
      "Recall: 0.975\n",
      "F1: 0.974\n",
      "        y=1    y=2   \n",
      " l=1   4924    140   \n",
      " l=2    125   4811   \n"
     ]
    }
   ],
   "source": [
    "print('Trained Label Model Metrics:')\n",
    "scores = label_model.score((data.L, data.Y), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4b: Compare to MajorityVote and No Class Balance+Dependencies LabelModel\n",
    "\n",
    "**Baseline: No Class Balance or Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[50 epo]: TRAIN:[loss=0.114]\n",
      "[100 epo]: TRAIN:[loss=0.017]\n",
      "[150 epo]: TRAIN:[loss=0.014]\n",
      "[200 epo]: TRAIN:[loss=0.014]\n",
      "[250 epo]: TRAIN:[loss=0.014]\n",
      "[300 epo]: TRAIN:[loss=0.014]\n",
      "[350 epo]: TRAIN:[loss=0.014]\n",
      "[400 epo]: TRAIN:[loss=0.014]\n",
      "[450 epo]: TRAIN:[loss=0.014]\n",
      "[500 epo]: TRAIN:[loss=0.014]\n",
      "Finished Training\n",
      "CPU times: user 14 s, sys: 88 ms, total: 14.1 s\n",
      "Wall time: 516 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from metal.label_model import LabelModel\n",
    "label_model = LabelModel(k=K, seed=123)\n",
    "\n",
    "label_model.train_model(data.L, lr=1e-3, n_epochs=500, log_train_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Label Model Metrics:\n",
      "Accuracy: 0.968\n",
      "Precision: 0.976\n",
      "Recall: 0.960\n",
      "F1: 0.968\n",
      "        y=1    y=2   \n",
      " l=1   4846    119   \n",
      " l=2    203   4832   \n"
     ]
    }
   ],
   "source": [
    "print('Trained Label Model Metrics:')\n",
    "scores = label_model.score((data.L, data.Y), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline: Majority Vote**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Label Voter Metrics:\n",
      "Accuracy: 0.967\n",
      "Precision: 0.973\n",
      "Recall: 0.961\n",
      "F1: 0.967\n",
      "        y=1    y=2   \n",
      " l=1   4854    135   \n",
      " l=2    195   4816   \n"
     ]
    }
   ],
   "source": [
    "from metal.label_model.baselines import MajorityLabelVoter\n",
    "\n",
    "mv = MajorityLabelVoter(k=K,seed=123)\n",
    "print('Majority Label Voter Metrics:')\n",
    "scores = mv.score((data.L, data.Y), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal]",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
