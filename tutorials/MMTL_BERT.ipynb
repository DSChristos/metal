{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMTL BERT Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This tutorial assumes that you have already completed the MMTL Basics tutorial.\n",
    "\n",
    "In this Tutorial, we demonstrate how the Snorkel MeTaL MMTL package can be used in a more advanced setting: more tasks, more complex modules (e.g., pretrained BERT), more complex data formatting (multiple fields), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we'll first make sure that we can import from `metal` alright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we can import from metal\n",
    "import sys\n",
    "sys.path.append('../../metal')\n",
    "import metal\n",
    "\n",
    "# Import other dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set random seed for notebook\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GLUE Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNUSED VERBIAGE:\n",
    "\n",
    "In this notebook, for simplicity and ease of visualization, we will solve two very simple geometric tasks; (see the `MMTL_BERT` tutorial for an example with more complex tasks):\n",
    "* Task 1: is \n",
    "\n",
    "Key Definitions:\n",
    "* **`Payload`**: A `Payload` is a set of instances (data points) and one or more corresponding label sets. In standard single-task settings or vanilla multi-task settings, each dataset is represented by a separate `Payload` with a single label set: the ground truth labels. In other settings, however, the same set of instances can have labels for multiple tasks (e.g., sentences with labels for both sentiment classification and topic classification) and/or multiple labels for the same task (e.g., one to three labels from different crowdworkers).\n",
    "\n",
    "* **`Task`**: A `Task` is a path through a network. In MeTaL, this corresponds to a particular sequence of Pytorch modules that each instance will pass through, ending with a \"task head\" module that outputs a prediction for that instance on that task.  `Task` objects are not restricted to work with only one `Payload` or label set.\n",
    "\n",
    "\n",
    "For illustration, consider two datasets: one containing tweets (the `Tweet` dataset) and the other containing product reviews (`Reviews`). In both cases, our goal is to predict the sentiment of the \"document\" (the tweet or review). However, our tweets have a label space of cardinality 2 (negative, positive), while our reviews have a label space of cardinality 3 (negative, neutral, positive). While there were certainly similarities between the two datasets (i.e., the word \"awful\" will suggest a negative sentiment in both domains), there are also differences (i.e., average number of words, different vocabulary distributions, etc.). This is a great candidate for multi-task learning.\n",
    "\n",
    "We start by defining a `Payload`. \n",
    "\n",
    "A `Payload` is a bundle of instances (data points) and one or more corresponding label sets. These are wrapped together in a Pytorch `DataLoader` that returns batches of data. A `Payload` also specifies the split that the data belongs to (e.g., 'train' or 'test') and a dictionary mapping each `LabelSet` to its corresponding `Task`.\n",
    "\n",
    "If the two problems in our MTL setup had disjoint instance sets, we would use two `Payloads`. As it is, \n",
    "\n",
    "usehave two related datasets with disjoint instances and only one label set---the gold labels---per instance set. This can be easily modeled using two `Payloads`.\n",
    "\n",
    " If your data has only one field (e.g., it is simply a Tensor), the default field_name is \"data\". Two advantages of storing data as a dictionary are that (1) it allows for additional fields to be added later with very few changes to the code, and (2) it supports working with models (such as BERT in NLP) that require multiple inputs per instance (e.g., token ids as well as segment ids).\n",
    " \n",
    " Instances and label sets are stored together in a Pytorch `Dataset` object.\n",
    "The `Dataset` is initilialized with an X dict and a Y dict:\n",
    "* The X dict is of the form {`field_name`: `values`}. The default field name is simply \"data\".\n",
    "* The Y dict of the form {`label_name`: `values`}.  The default label set name is simply \"labels\".\n",
    "\n",
    "For example, metrics are reported in the form \"task/payload/label_set/metric\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal] *",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
