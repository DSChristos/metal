{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metal CDR Relation Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/dfs/scratch0/vschen/metal')\n",
    "import metal\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch:  1.0.0\n",
      "MeTaL:    0.3.3\n",
      "Python:   3.6.7 (default, Dec  8 2018, 17:35:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Python:   sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch: ', torch.__version__)\n",
    "print('MeTaL:   ', metal.__version__)\n",
    "print('Python:  ', sys.version)\n",
    "print('Python:  ', sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalize CDR Dataset\n",
    "To uncompress the SQLite db: ```bzip2 -d cdr.db.bz2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to sqlite:////dfs/scratch0/vschen/metal/metal/contrib/backends/cdr.db\n",
      "Connected to sqlite:////dfs/scratch0/vschen/metal/metal/contrib/backends/cdr.db\n",
      "Connected to sqlite:////dfs/scratch0/vschen/metal/metal/contrib/backends/cdr.db\n",
      "[TRAIN] 8272\n",
      "[DEV]   888\n",
      "[TEST]  4620\n"
     ]
    }
   ],
   "source": [
    "from metal.contrib.backends.wrapper import SnorkelDataset\n",
    "import os\n",
    "\n",
    "db_conn_str   = os.path.join(os.getcwd(),\"cdr.db\")\n",
    "candidate_def = ['ChemicalDisease', ['chemical', 'disease']]\n",
    "\n",
    "train, dev, test = SnorkelDataset.splits(db_conn_str, \n",
    "                                         candidate_def, \n",
    "                                         max_seq_len=125)\n",
    "\n",
    "print(f'[TRAIN] {len(train)}')\n",
    "print(f'[DEV]   {len(dev)}')\n",
    "print(f'[TEST]  {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 1500\n",
      "Sentences: 14001\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import Document, Sentence\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from six.moves.cPickle import load\n",
    "\n",
    "with bz2.BZ2File('data/ctd.pkl.bz2', 'rb') as ctd_f:\n",
    "    ctd_unspecified, ctd_therapy, ctd_marker = load(ctd_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_in_ctd_unspecified(c):\n",
    "    return 1 if c.get_cids() in ctd_unspecified else 0\n",
    "\n",
    "def cand_in_ctd_therapy(c):\n",
    "    return 1 if c.get_cids() in ctd_therapy else 0\n",
    "\n",
    "def cand_in_ctd_marker(c):\n",
    "    return 1 if c.get_cids() in ctd_marker else 0\n",
    "\n",
    "def LF_in_ctd_unspecified(c):\n",
    "    return -1 * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_in_ctd_therapy(c):\n",
    "    return -1 * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_in_ctd_marker(c):\n",
    "    return cand_in_ctd_marker(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "def LF_induce(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "def LF_d_induced_by_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return 1 if 'induc' in c.chemical.get_span().lower() else 0     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "def LF_d_treat_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_treat_d(c):\n",
    "    return rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d_wide(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return 1 if ('{{A}} {{B}}' in get_tagged_text(c)) else 0\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return 1 if (\n",
    "        ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else 0\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    return rule_regex_search_before_B(c, 'improv.*', -1)\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return -1 if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    return rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    return rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)\n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_far_d_c(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    return rule_regex_search_before_B(c, 'risk of ', 1)\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return 1 if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "procedure, following = ['inject', 'administrat'], ['following']\n",
    "def LF_d_following_c(c):\n",
    "    return 1 if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_measure(c):\n",
    "    return -1 if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_level(c):\n",
    "    return -1 if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return -1 if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return -1 if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_ctd_marker_c_d(c):\n",
    "    return LF_c_d(c) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_marker_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_therapy_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_ctd_unspecified_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_ctd_unspecified_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_unspecified(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_closer_chem(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical closer than @dist/2 in either direction\n",
    "    sent = c.get_parent()\n",
    "    closest_other_chem = float('inf')\n",
    "    for i in range(dis_end, min(len(sent.words), dis_end + dist // 2)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, dis_start - dist // 2), dis_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_closer_dis(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical disease than @dist/8 in either direction\n",
    "    sent = c.get_parent()\n",
    "    for i in range(chem_end, min(len(sent.words), chem_end + dist // 8)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, chem_start - dist // 8), chem_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    LF_c_cause_d,\n",
    "    LF_c_d,\n",
    "    LF_c_induced_d,\n",
    "    LF_c_treat_d,\n",
    "    LF_c_treat_d_wide,\n",
    "    LF_closer_chem,\n",
    "    LF_closer_dis,\n",
    "    LF_ctd_marker_c_d,\n",
    "    LF_ctd_marker_induce,\n",
    "    LF_ctd_therapy_treat,\n",
    "    LF_ctd_unspecified_treat,\n",
    "    LF_ctd_unspecified_induce,\n",
    "    LF_d_following_c,\n",
    "    LF_d_induced_by_c,\n",
    "    LF_d_induced_by_c_tight,\n",
    "    LF_d_treat_c,\n",
    "    LF_develop_d_following_c,\n",
    "    LF_far_c_d,\n",
    "    LF_far_d_c,\n",
    "    LF_improve_before_disease,\n",
    "    LF_in_ctd_therapy,\n",
    "    LF_in_ctd_marker,\n",
    "    LF_in_patient_with,\n",
    "    LF_induce,\n",
    "    LF_induce_name,\n",
    "    LF_induced_other,\n",
    "    LF_level,\n",
    "    LF_measure,\n",
    "    LF_neg_d,\n",
    "    LF_risk_d,\n",
    "    LF_treat_d,\n",
    "    LF_uncertain,\n",
    "    LF_weak_assertions,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/8272 [00:00<02:20, 58.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8272/8272 [00:38<00:00, 212.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 s, sys: 304 ms, total: 38.7 s\n",
      "Wall time: 39.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<8272x33 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20079 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel(lf_propensity=True)\n",
    "gen_model.train(\n",
    "    L_train, deps=deps, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to sqlite:////dfs/scratch0/vschen/metal/metal/contrib/backends/cdr.db\n"
     ]
    }
   ],
   "source": [
    "from metal.contrib.backends.wrapper import SnorkelDataset\n",
    "train_slice = SnorkelDataset(\n",
    "    db_conn_str,\n",
    "    candidate_def,\n",
    "    split=0,\n",
    "    L_train=L_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using randomly initialized embeddings.\n",
      "Embeddings shape = (9946, 50)\n",
      "The embeddings are NOT FROZEN\n",
      "Using lstm_reduction = 'attention'\n"
     ]
    }
   ],
   "source": [
    "from metal.end_model import EndModel\n",
    "from metal.modules import LSTMModule\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "lstm = LSTMModule(embed_size=50, \n",
    "                  hidden_size=100, \n",
    "                  vocab_size=train.word_dict.len(),\n",
    "                  lstm_reduction='attention', \n",
    "                  dropout=0,\n",
    "                  num_layers=1, \n",
    "                  freeze=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Slice Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/snorkel/snorkel/learning/gen_learning.py:350: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"Precision\": tp / (tp + fp),\n",
      "/dfs/scratch0/vschen/snorkel/snorkel/learning/gen_learning.py:352: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"Accuracy\": (tp + tn) / coverage,\n",
      "/dfs/scratch0/vschen/snorkel-pytorch/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/dfs/scratch0/vschen/metal/metal/contrib/slicing/online_dp.py:102: RuntimeWarning: divide by zero encountered in log\n",
      "  self.w = torch.from_numpy(np.log(accs / (1-accs))).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice Heads:\n",
      "Input Network: Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): LSTMModule(\n",
      "      (embeddings): Embedding(9946, 50)\n",
      "      (lstm): LSTM(50, 100, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "L_head: Linear(in_features=200, out_features=33, bias=False)\n",
      "Y_head: Linear(in_features=400, out_features=2, bias=False)\n"
     ]
    }
   ],
   "source": [
    "from metal.contrib.slicing.online_dp import SliceDPModel, LinearModule\n",
    "from metal.modules import LSTMModule\n",
    "\n",
    "r_dim = 200\n",
    "rw = True\n",
    "accs = np.array(gen_model.learned_lf_stats()['Accuracy'])\n",
    "accs[np.isnan(accs)] = 0\n",
    "accs = np.minimum(accs, 0.999)\n",
    "slice_model = SliceDPModel(lstm, accs, r_dim, rw, seed=123, use_cuda=True)\n",
    "\n",
    "slice_model.config['train_config']['optimizer_config']['optimizer_common']['lr'] = 0.01\n",
    "slice_model.config['train_config']['validation_metric'] = 'f1'\n",
    "slice_model.config['train_config']['batch_size'] = 32\n",
    "slice_model.config['train_config']['n_epochs'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda0ecd79a0445f839258ecec7d263f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/snorkel-pytorch/venv/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/dfs/scratch0/vschen/metal/metal/contrib/slicing/online_dp.py:167: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  A = F.softmax(self.forward_L(x)).unsqueeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 0 with best score 0.524\n",
      "[E:0]\tTrain Loss: 0.444\tDev f1: 0.524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b836d1df254c4981a784ad9f115888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 1 with best score 0.539\n",
      "[E:1]\tTrain Loss: 0.433\tDev f1: 0.539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d66c05ba284de5a57fe712ab194fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 2 with best score 0.544\n",
      "[E:2]\tTrain Loss: 0.426\tDev f1: 0.544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429c0d03d8b64aafbec5ef6ad4b9dd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 3 with best score 0.577\n",
      "[E:3]\tTrain Loss: 0.422\tDev f1: 0.577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37987aa9dd1423c8adcf9342977d261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:4]\tTrain Loss: 0.419\tDev f1: 0.560\n",
      "Restoring best model from iteration 3 with score 0.577\n",
      "Finished Training\n",
      "F1: 0.577\n",
      "        y=1    y=2   \n",
      " l=1    271    373   \n",
      " l=2    25     219   \n",
      "CPU times: user 17min 38s, sys: 21.3 s, total: 17min 59s\n",
      "Wall time: 17min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "slice_model.train_model(train_slice, dev_data=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.400\n",
      "Recall: 0.908\n",
      "F1: 0.555\n",
      "        y=1    y=2   \n",
      " l=1   1367   2054   \n",
      " l=2    138   1061   \n"
     ]
    }
   ],
   "source": [
    "score = slice_model.score(test, metric=['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train End Model (Random Initalized Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): LSTMModule(\n",
      "      (embeddings): Embedding(9946, 50)\n",
      "      (lstm): LSTM(50, 100, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (1): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "end_model = EndModel([200, 2], input_module=lstm, seed=123, use_cuda=use_cuda)\n",
    "\n",
    "end_model.config['train_config']['optimizer_config']['optimizer_common']['lr'] = 0.01\n",
    "end_model.config['train_config']['validation_metric'] = 'f1'\n",
    "end_model.config['train_config']['batch_size'] = 32\n",
    "end_model.config['train_config']['n_epochs'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af378ab2c7d84420b595c9dbb99491a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 0 with best score 0.604\n",
      "[E:0]\tTrain Loss: 0.399\tDev f1: 0.604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6b08b83bce426b978b129ad09fc40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:1]\tTrain Loss: 0.228\tDev f1: 0.584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf8d6428de0437ab13bc207881b4770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 2 with best score 0.619\n",
      "[E:2]\tTrain Loss: 0.144\tDev f1: 0.619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac333e52ffa448f8200411f6a431a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:3]\tTrain Loss: 0.104\tDev f1: 0.480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02a612e6d8c4358a6f6781b18273103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:4]\tTrain Loss: 0.086\tDev f1: 0.616\n",
      "Restoring best model from iteration 2 with score 0.619\n",
      "Finished Training\n",
      "F1: 0.619\n",
      "        y=1    y=2   \n",
      " l=1    186    119   \n",
      " l=2    110    473   \n",
      "CPU times: user 6min 39s, sys: 8.69 s, total: 6min 48s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "end_model.train_model(train, dev_data=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.544\n",
      "Recall: 0.619\n",
      "F1: 0.579\n",
      "        y=1    y=2   \n",
      " l=1    931    780   \n",
      " l=2    574   2335   \n"
     ]
    }
   ],
   "source": [
    "score = end_model.score(test, metric=['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train End Model (Pretrained Embeddings)\n",
    "\n",
    "Download [GloVe embeddings](http://nlp.stanford.edu/data/glove.6B.zip):\n",
    "`wget http://nlp.stanford.edu/data/glove.6B.zip \\\n",
    "&& mkdir -p glove.6B \\\n",
    "&& unzip glove.6B.zip -d glove.6B \\\n",
    "&& rm glove.6B.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "class EmbeddingLoader(object):\n",
    "    \"\"\"\n",
    "    Simple text file embedding loader. Words with GloVe and FastText.\n",
    "    \"\"\"\n",
    "    def __init__(self, fpath, fmt='text', dim=None, normalize=True):\n",
    "        assert os.path.exists(fpath)\n",
    "        self.fpath = fpath\n",
    "        self.dim = dim\n",
    "        self.fmt = fmt\n",
    "        # infer dimension\n",
    "        if not self.dim:\n",
    "            header = open(self.fpath, \"rU\").readline().strip().split(' ')\n",
    "            self.dim = len(header) - 1 if len(header) != 2 else int(header[-1])\n",
    "\n",
    "        self.vocab, self.vectors = zip(*[(w,vec) for w,vec in self._read()])\n",
    "        self.vocab = {w:i for i,w in enumerate(self.vocab)}\n",
    "        self.vectors = np.vstack(self.vectors)\n",
    "        if normalize:\n",
    "            self.vectors = (self.vectors.T / np.linalg.norm(self.vectors, axis=1, ord=2)).T\n",
    "\n",
    "    def _read(self):\n",
    "        start = 0 if self.fmt == \"text\" else 1\n",
    "        for i, line in enumerate(open(self.fpath, \"rU\")):\n",
    "            if i < start:\n",
    "                continue\n",
    "            line = line.rstrip().split(' ')\n",
    "            vec = np.array([float(x) for x in line[1:]])\n",
    "            if len(vec) != self.dim:\n",
    "                errors += [line[0]]\n",
    "                continue\n",
    "            yield (line[0], vec)\n",
    "            \n",
    "\n",
    "def load_embeddings(vocab, embeddings):\n",
    "    \"\"\"\n",
    "    Load pretrained embeddings\n",
    "    \"\"\"\n",
    "    def get_word_match(w, word_dict):\n",
    "        if w in word_dict:\n",
    "            return word_dict[w]\n",
    "        elif w.lower() in word_dict:\n",
    "            return word_dict[w.lower()]\n",
    "        elif w.strip(string.punctuation) in word_dict:\n",
    "            return word_dict[w.strip(string.punctuation)]\n",
    "        elif w.strip(string.punctuation).lower() in word_dict:\n",
    "            return word_dict[w.strip(string.punctuation).lower()]\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    num_words = vocab.len()\n",
    "    emb_dim   = embeddings.vectors.shape[1]\n",
    "    vecs      = init.xavier_normal_(torch.empty(num_words, emb_dim))\n",
    "    vecs[0]   = torch.zeros(emb_dim)\n",
    "\n",
    "    n = 0\n",
    "    for w in vocab.d:\n",
    "        idx = get_word_match(w, embeddings.vocab)\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        i = vocab.lookup(w)\n",
    "        vecs[i] = torch.FloatTensor(embeddings.vectors[idx])\n",
    "        n += 1\n",
    "\n",
    "    print(\"Loaded {:2.1f}% ({}/{}) pretrained embeddings\".format(float(n) / vocab.len() * 100.0, n, vocab.len() ))\n",
    "    return vecs         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/snorkel-pytorch/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: 'U' mode is deprecated\n",
      "/dfs/scratch0/vschen/snorkel-pytorch/venv/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    }
   ],
   "source": [
    "emb_path  = \"glove.6B/glove.6B.50d.txt\"\n",
    "embs  = EmbeddingLoader(emb_path, fmt='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to sqlite:///cdr.db\n",
      "Connected to sqlite:///cdr.db\n",
      "Connected to sqlite:///cdr.db\n",
      "[TRAIN] 8272\n",
      "[DEV]   888\n",
      "[TEST]  4620\n"
     ]
    }
   ],
   "source": [
    "from metal.contrib.backends.wrapper import SnorkelDataset\n",
    "\n",
    "db_conn_str   = \"cdr.db\"\n",
    "candidate_def = ['ChemicalDisease', ['chemical', 'disease']]\n",
    "\n",
    "train, dev, test = SnorkelDataset.splits(db_conn_str, \n",
    "                                         candidate_def, \n",
    "                                         pretrained_word_dict=embs.vocab, \n",
    "                                         max_seq_len=125)\n",
    "\n",
    "print(f'[TRAIN] {len(train)}')\n",
    "print(f'[DEV]   {len(dev)}')\n",
    "print(f'[TEST]  {len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize pretrained embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 79.9% (9116/11406) pretrained embeddings\n"
     ]
    }
   ],
   "source": [
    "wembs = load_embeddings(train.word_dict, embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained embeddings.\n",
      "Embeddings shape = (11406, 50)\n",
      "The embeddings are NOT FROZEN\n",
      "Using lstm_reduction = 'attention'\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): LSTMModule(\n",
      "      (embeddings): Embedding(11406, 50)\n",
      "      (lstm): LSTM(50, 100, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (1): Linear(in_features=200, out_features=2, bias=True)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metal.end_model import EndModel\n",
    "from metal.modules import LSTMModule\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "lstm = LSTMModule(embed_size=50, \n",
    "                  hidden_size=100, \n",
    "                  embeddings=wembs,\n",
    "                  lstm_reduction='attention', \n",
    "                  dropout=0, \n",
    "                  num_layers=1, \n",
    "                  freeze=False)\n",
    "\n",
    "end_model = EndModel([200, 2], input_module=lstm, seed=123, use_cuda=use_cuda)\n",
    "\n",
    "end_model.config['train_config']['optimizer_config']['optimizer_common']['lr'] = 0.01\n",
    "end_model.config['train_config']['validation_metric'] = 'f1'\n",
    "end_model.config['train_config']['batch_size'] = 32\n",
    "end_model.config['train_config']['n_epochs'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f32fc1fe1bb4839825351df56962876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 0 with best score 0.599\n",
      "[E:0]\tTrain Loss: 0.533\tDev f1: 0.599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469c6ac3e15c46bcbb7be6b0570ef6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:1]\tTrain Loss: 0.293\tDev f1: 0.568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622d181b83824af4b9b53d3a26243307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:2]\tTrain Loss: 0.174\tDev f1: 0.560\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6bf4963ab44aba9818fdd1005a7015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:3]\tTrain Loss: 0.119\tDev f1: 0.585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243eedf4e8154cd8a190d6ab28526556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:4]\tTrain Loss: 0.078\tDev f1: 0.575\n",
      "Restoring best model from iteration 0 with score 0.599\n",
      "Finished Training\n",
      "F1: 0.599\n",
      "        y=1    y=2   \n",
      " l=1    191    151   \n",
      " l=2    105    441   \n",
      "CPU times: user 6min 19s, sys: 9.48 s, total: 6min 28s\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "end_model.train_model(train, dev_data=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.526\n",
      "Recall: 0.658\n",
      "F1: 0.585\n",
      "        y=1    y=2   \n",
      " l=1    990    892   \n",
      " l=2    515   2223   \n"
     ]
    }
   ],
   "source": [
    "score = end_model.score(test, metric=['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice Heads:\n",
      "Input Network: Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): LSTMModule(\n",
      "      (embeddings): Embedding(11406, 50)\n",
      "      (lstm): LSTM(50, 100, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "L_head: Linear(in_features=200, out_features=33, bias=False)\n",
      "Y_head: Linear(in_features=400, out_features=2, bias=False)\n"
     ]
    }
   ],
   "source": [
    "from metal.contrib.slicing.online_dp import SliceDPModel, LinearModule\n",
    "from metal.modules import LSTMModule\n",
    "\n",
    "r_dim = 200\n",
    "rw = True\n",
    "accs = np.array(gen_model.learned_lf_stats()['Accuracy'])\n",
    "accs[np.isnan(accs)] = 0\n",
    "accs = np.minimum(accs, 0.999)\n",
    "slice_model = SliceDPModel(lstm, accs, r_dim, rw, seed=123, use_cuda=True)\n",
    "\n",
    "slice_model.config['train_config']['optimizer_config']['optimizer_common']['lr'] = 0.01\n",
    "slice_model.config['train_config']['validation_metric'] = 'f1'\n",
    "slice_model.config['train_config']['batch_size'] = 32\n",
    "slice_model.config['train_config']['n_epochs'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff65616019444ff780240cf0337e4095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 0 with best score 0.526\n",
      "[E:0]\tTrain Loss: 0.439\tDev f1: 0.526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac84d0bc58f4dc5b3a1065169a3cf05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 1 with best score 0.543\n",
      "[E:1]\tTrain Loss: 0.428\tDev f1: 0.543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051cb5a4f03d4697830929dea563b497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:2]\tTrain Loss: 0.422\tDev f1: 0.532\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f9b32c13cd44dd8f44fa715234f05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model at iteration 3 with best score 0.550\n",
      "[E:3]\tTrain Loss: 0.418\tDev f1: 0.550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b970c27d96a49ddb2dc1291040ddb37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[E:4]\tTrain Loss: 0.416\tDev f1: 0.541\n",
      "Restoring best model from iteration 3 with score 0.550\n",
      "Finished Training\n",
      "F1: 0.550\n",
      "        y=1    y=2   \n",
      " l=1    261    392   \n",
      " l=2    35     200   \n",
      "CPU times: user 17min 38s, sys: 22.3 s, total: 18min\n",
      "Wall time: 17min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "slice_model.train_model(train_slice, dev_data=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.396\n",
      "Recall: 0.896\n",
      "F1: 0.549\n",
      "        y=1    y=2   \n",
      " l=1   1349   2061   \n",
      " l=2    156   1054   \n"
     ]
    }
   ],
   "source": [
    "score = slice_model.score(test, metric=['precision', 'recall', 'f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
