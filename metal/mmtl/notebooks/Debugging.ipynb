{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "import metal.mmtl.dataset as dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from metal.mmtl.bert_tasks import create_tasks\n",
    "from metal.mmtl.metal_model import MetalModel\n",
    "from metal.mmtl.scorer import Scorer\n",
    "from metal.utils import convert_labels\n",
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/dfs/scratch0/jdunnmon/mmtl/sota_quest/debugging/COLA/COLA_19_48_08/best_model.pth'\n",
    "csv_path = \"/\".join(model_path.split('/')[0:-2]) #set to -1 if permissions exist\n",
    "task_name = model_path.split('/')[-3]\n",
    "\n",
    "bert_model = 'bert-base-uncased'\n",
    "max_len = 256\n",
    "bert_output_dim = 768\n",
    "dl_kwargs = {\"batch_size\": 32, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b688534300c4564ba6c912cf9607527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1043), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading COLA Dataset\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f2647981324010b57019a5724ffa82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2d2eab9e5f4441a1328d086e656024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Get DataLoader\n",
    "dataset_cls = getattr(dataset, task_name.upper() + \"Dataset\")\n",
    "dev_ds = dataset_cls(\n",
    "    split=\"dev\",\n",
    "    bert_model=bert_model,\n",
    "    max_len=max_len,\n",
    "    max_datapoints=-1,\n",
    ")\n",
    "dev_dl = dev_ds.get_dataloader(**dl_kwargs)\n",
    "\n",
    "#Load best model for specified task\n",
    "tasks = create_tasks(\n",
    "        task_names=[task_name],\n",
    "        bert_model=bert_model,\n",
    "        split_prop=0.8,\n",
    "        max_len=max_len,\n",
    "        dl_kwargs={\"batch_size\": 1},\n",
    "        bert_output_dim=bert_output_dim,\n",
    "        max_datapoints=10,\n",
    "    )\n",
    "\n",
    "model = MetalModel(tasks, verbose=False, device=-1)\n",
    "model.load_state_dict(torch.load(model_path)['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DataFrame of Predictions and True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 33.00it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'sentence1': [],\n",
    "    'sentence2': [],\n",
    "    'label': [],\n",
    "    'score' : []\n",
    "}\n",
    "max_batches = 100\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
    "from tqdm import tqdm\n",
    "count = 0\n",
    "for x, y in tqdm(list(dev_dl)):\n",
    "    for tokens_idx in x[0]:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokens_idx.numpy())\n",
    "        phrases = ' '.join(tokens).replace('[PAD]', '').replace('[CLS]', '').split('[SEP]')\n",
    "        data['sentence1'] += [phrases[0]]\n",
    "        if len(phrases) > 1:\n",
    "            data['sentence2'] += [phrases[1]] \n",
    "        else:\n",
    "            data['sentence2'] += ['NA']\n",
    "    scores = model.calculate_output(x, [task_name])[task_name].detach().cpu().numpy()[:, 0] # .flatten()\n",
    "    data['score'] += list(scores)\n",
    "    data['label'] += list(convert_labels(y, 'categorical', 'onezero').numpy())\n",
    "    count += 1\n",
    "    if count > max_batches:\n",
    "        break\n",
    "        \n",
    "\n",
    "df_error = pd.DataFrame(data, columns=['sentence1', 'sentence2', 'score', 'label'])\n",
    "df_error['pred'] = 1* (df_error.score > 0.5)\n",
    "df_error['is_wrong'] = df_error['pred'] != df_error['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Error DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe to:  /dfs/scratch0/jdunnmon/mmtl/sota_quest/debugging/COLA/dev_error_analysis.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the sailors rode the breeze clear of the rock...</td>\n",
       "      <td></td>\n",
       "      <td>0.987432</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the weights made the rope stretch over the pu...</td>\n",
       "      <td></td>\n",
       "      <td>0.992936</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the mechanical doll wr ##ig ##gled itself loo...</td>\n",
       "      <td></td>\n",
       "      <td>0.226052</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>if you had eaten more , you would want less .</td>\n",
       "      <td></td>\n",
       "      <td>0.988117</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>as you eat the most , you want the least .</td>\n",
       "      <td></td>\n",
       "      <td>0.131787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          sentence1 sentence2  \\\n",
       "0           0   the sailors rode the breeze clear of the rock...             \n",
       "1           1   the weights made the rope stretch over the pu...             \n",
       "2           2   the mechanical doll wr ##ig ##gled itself loo...             \n",
       "3           3     if you had eaten more , you would want less .              \n",
       "4           4        as you eat the most , you want the least .              \n",
       "\n",
       "      score  label  pred  is_wrong  \n",
       "0  0.987432      1     1     False  \n",
       "1  0.992936      1     1     False  \n",
       "2  0.226052      1     0      True  \n",
       "3  0.988117      1     1     False  \n",
       "4  0.131787      0     0     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_dataframe(df,filepath):\n",
    "    df.to_csv(filepath, sep='\\t')\n",
    "    print('Saved dataframe to: ', filepath)\n",
    "    \n",
    "def load_dataframe(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    return df\n",
    "\n",
    "filepath = f'{csv_path}/dev_error_analysis.tsv'\n",
    "save_dataframe(df_error,filepath)\n",
    "df_error = load_dataframe(filepath)\n",
    "df_error.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_random_pred(df):\n",
    "    row = df.iloc[np.random.randint(df.shape[0])]\n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINCORRECT PREDICTIONS\u001b[0;0m\n",
      "sentence1: \t john was tall , but i don ' t know on what occasions . \n",
      "sentence2: \t      \n",
      "score: \t0.9735\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t john and someone were dancing together , but i don ' t know who . \n",
      "sentence2: \t                  \n",
      "score: \t0.9914\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t chocolate eggs were hidden from each other by the children . \n",
      "sentence2: \t   \n",
      "score: \t0.9957\n",
      "label: \t0\n",
      "\n",
      "\u001b[1mCORRECT PREDICTIONS\u001b[0;0m\n",
      "sentence1: \t i know which book jose didn ' t read for class , and which book lilly did it for him . \n",
      "sentence2: \tnan\n",
      "score: \t0.3956\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t mike talked about politics yesterday to my friends . \n",
      "sentence2: \t                  \n",
      "score: \t0.9911\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t i know the person whose mother died . \n",
      "sentence2: \t                       \n",
      "score: \t0.9920\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mINCORRECT PREDICTIONS\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_random_pred(df_error[df_error.is_wrong==True])\n",
    "    print()\n",
    "    \n",
    "print(\"\\033[1mCORRECT PREDICTIONS\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_random_pred(df_error[df_error.is_wrong==False])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox for Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. We want to look at examples that are \"barely\" wrong and \"barely\" right since we have hope for boosts here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_barely_wrong_pred(df,thresh=0.05):\n",
    "    df_temp = df[df.is_wrong==True]\n",
    "    idx = np.where(np.abs(df_temp.score - 0.5) <= thresh)[0]\n",
    "    row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')  \n",
    "    \n",
    "def print_barely_right_pred(df,thresh=0.05):\n",
    "    df_temp = df[df.is_wrong==False]\n",
    "    idx = np.where(np.abs(df_temp.score - 0.5) <= thresh)[0]\n",
    "    row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBARELY WRONG\u001b[0;0m\n",
      "sentence1: \t where did you go and who ate what ? \n",
      "sentence2: \t                  \n",
      "score: \t0.4711\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t was sunk . \n",
      "sentence2: \t            \n",
      "score: \t0.5241\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t med ##ea denied poisoning the phoenix . \n",
      "sentence2: \t       \n",
      "score: \t0.4856\n",
      "label: \t1\n",
      "\n",
      "\u001b[1mBARELY RIGHT\u001b[0;0m\n",
      "sentence1: \t who is she trying to make up to now ? \n",
      "sentence2: \t                 \n",
      "score: \t0.5353\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t who is she trying to make up to now ? \n",
      "sentence2: \t                 \n",
      "score: \t0.5353\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t who is she trying to make up to now ? \n",
      "sentence2: \t                 \n",
      "score: \t0.5353\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mBARELY WRONG\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_barely_wrong_pred(df_error)\n",
    "    print()\n",
    "    \n",
    "print(\"\\033[1mBARELY RIGHT\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_barely_right_pred(df_error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. We also want to look at examples we got completely wrong since that could point to a systematic bias in the data/model. It could also help us find examples in the dataset that are mislabeled by human annotators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_very_wrong_pred(df,thresh=0.95):\n",
    "    df_temp = df[df.is_wrong==True]\n",
    "    idx = np.where(np.abs(df_temp.score - df_temp.label) >= thresh)[0]\n",
    "    row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVERY WRONG\u001b[0;0m\n",
      "sentence1: \t john and someone were dancing together , but i don ' t know who . \n",
      "sentence2: \t                  \n",
      "score: \t0.9914\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t the paper was written by john up . \n",
      "sentence2: \t      \n",
      "score: \t0.9642\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t we gave us presents . \n",
      "sentence2: \t          \n",
      "score: \t0.9950\n",
      "label: \t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mVERY WRONG\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_very_wrong_pred(df_error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. To find systematic errors, we can also look for correlations between certain features and the incorrectness a la Socratic**\n",
    "\n",
    "\n",
    "We can make this way more sophisticated by perhaps using embeddings instead of this simple [BoW featurization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/venv-mmtl/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a vector of correct/incorrect predictions\n",
    "y = 2*(np.array(df_error.is_wrong.astype(float))-0.5)\n",
    "\n",
    "#Create BoW featurization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = np.array(list(df_error.sentence1))\n",
    "vectorizer = CountVectorizer(ngram_range=(2,5), stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "#Run LR to find correlations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(penalty=\"l1\")\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ega tion\n",
      "john believes\n",
      "john bought\n",
      "john eat\n",
      "don know\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.stem(np.sort(np.abs(lr_model.coef_)[0])[::-1][0:50])\n",
    "plt.title('Feature Coefficient')\n",
    "plt.xlabel('Top k Features')\n",
    "\n",
    "top_idx = np.argsort(np.abs(lr_model.coef_)[0])[::-1][0:50]\n",
    "names = vectorizer.get_feature_names()\n",
    "for i in range(5):\n",
    "    print (names[top_idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSYSTEMATIC EXAMPLES\u001b[0;0m\n",
      "sentence1: \t the defendant deny the all ##ega ##tion . \n",
      "sentence2: \t            \n",
      "score: \t0.9753\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t the defendants denies the all ##ega ##tion . \n",
      "sentence2: \t            \n",
      "score: \t0.9711\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t john believes it that bill is here . \n",
      "sentence2: \t         \n",
      "score: \t0.5245\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t john believes it sincerely that bill is here . \n",
      "sentence2: \t        \n",
      "score: \t0.9850\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t john bought a book on the table . \n",
      "sentence2: \t       \n",
      "score: \t0.0600\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t john bought a dog for himself to play with . \n",
      "sentence2: \t \n",
      "score: \t0.9941\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i demand that the more john eat , the more he pays . \n",
      "sentence2: \t    \n",
      "score: \t0.8997\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t agnes wondered how john could eat but it ' s not clear what . \n",
      "sentence2: \t                   \n",
      "score: \t0.9099\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i don ' t know if i should agree . \n",
      "sentence2: \t     \n",
      "score: \t0.9927\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t john ate dinner but i don ' t know who . \n",
      "sentence2: \t         \n",
      "score: \t0.7922\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t she mail ##ed john a letter , but i don ' t know to whom . \n",
      "sentence2: \t    \n",
      "score: \t0.9697\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t the ship sank , but i don ' t know with what . \n",
      "sentence2: \t       \n",
      "score: \t0.9200\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t they noticed the painting , but i don ' t know for how long . \n",
      "sentence2: \t     \n",
      "score: \t0.9904\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t john was tall , but i don ' t know on what occasions . \n",
      "sentence2: \t      \n",
      "score: \t0.9735\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t joan ate dinner with someone but i don ' t know who . \n",
      "sentence2: \t       \n",
      "score: \t0.9139\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t joan ate dinner with someone but i don ' t know who with . \n",
      "sentence2: \t                \n",
      "score: \t0.0296\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t i know that meg ' s attracted to harry , but they don ' t know who . \n",
      "sentence2: \t            \n",
      "score: \t0.9884\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i know that meg ' s attracted to harry , but they don ' t know who . \n",
      "sentence2: \t            \n",
      "score: \t0.9880\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t john likes some students , but i don ' t know who . \n",
      "sentence2: \t                 \n",
      "score: \t0.9882\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t i don ' t know who john likes . \n",
      "sentence2: \t                     \n",
      "score: \t0.9939\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t john likes some students , but i don ' t know who john likes some students . \n",
      "sentence2: \t             \n",
      "score: \t0.7321\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t she talked to john or mary but i don ' t know which . \n",
      "sentence2: \t                \n",
      "score: \t0.8666\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t she talked to john or mary but i don ' t know which one . \n",
      "sentence2: \t               \n",
      "score: \t0.5599\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t she talked to harry , but i don ' t know who else . \n",
      "sentence2: \t                \n",
      "score: \t0.1508\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t i will see them , but i don ' t know how many of them . \n",
      "sentence2: \t              \n",
      "score: \t0.9047\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t she said she talked to three students but i don ' t know how many . \n",
      "sentence2: \t                 \n",
      "score: \t0.8976\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t she said she talked to those students but i don ' t know how many . \n",
      "sentence2: \t                 \n",
      "score: \t0.5858\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t he shouted again , but i don ' t know who to . \n",
      "sentence2: \t                    \n",
      "score: \t0.4538\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t she was dancing with somebody , but i don ' t know who with . \n",
      "sentence2: \t                  \n",
      "score: \t0.0238\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t meg is attracted to harry , but they don ' t know who she is attracted to . \n",
      "sentence2: \t               \n",
      "score: \t0.9921\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t john and someone were dancing together , but i don ' t know who . \n",
      "sentence2: \t                  \n",
      "score: \t0.9914\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i know how many assignments i ' ve graded , but i don ' t know how many bill has . \n",
      "sentence2: \t            \n",
      "score: \t0.9520\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t she ' s been dancing but we don ' t know with whom . \n",
      "sentence2: \t                   \n",
      "score: \t0.9637\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mSYSTEMATIC EXAMPLES\\033[0;0m\")\n",
    "for i in range(5):\n",
    "    idx = list(np.where(X.todense()[:,top_idx[i]] == 1)[0])\n",
    "    for ii in range(len(idx)):\n",
    "        df_temp = df_error\n",
    "        row = df_temp.iloc[idx[ii]]\n",
    "\n",
    "        print(f'sentence1: \\t{row.sentence1}')\n",
    "        print(f'sentence2: \\t{row.sentence2}')\n",
    "        print('score: \\t{:.4f}'.format(row.score))    \n",
    "        print(f'label: \\t{row.label}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
