{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "import metal.mmtl.dataset as dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from metal.mmtl.bert_tasks import create_tasks\n",
    "from metal.mmtl.metal_model import MetalModel\n",
    "from metal.mmtl.scorer import Scorer\n",
    "from metal.utils import convert_labels\n",
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = '/dfs/scratch0/jdunnmon/mmtl/sota_quest/debugging/COLA/COLA_19_48_08/best_model.pth'\n",
    "model_path = '/dfs/scratch0/jdunnmon/mmtl/sota_quest/debugging/RTE/RTE_16_35_57/best_model.pth'\n",
    "csv_path = \"/\".join(model_path.split('/')[0:-2]) #set to -1 if permissions exist\n",
    "task_name = model_path.split('/')[-3]\n",
    "\n",
    "bert_model = 'bert-base-uncased'\n",
    "max_len = 256\n",
    "bert_output_dim = 768\n",
    "dl_kwargs = {\"batch_size\": 32, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f4c02022734c4681a98d636e3161ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=277), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading RTE Dataset\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7364552e544201afafc8000a2440a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9fdb178dd847c698a60b6db2a592fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Get DataLoader\n",
    "dataset_cls = getattr(dataset, task_name.upper() + \"Dataset\")\n",
    "dev_ds = dataset_cls(\n",
    "    split=\"dev\",\n",
    "    bert_model=bert_model,\n",
    "    max_len=max_len,\n",
    "    max_datapoints=-1,\n",
    ")\n",
    "dev_dl = dev_ds.get_dataloader(**dl_kwargs)\n",
    "\n",
    "#Load best model for specified task\n",
    "tasks = create_tasks(\n",
    "        task_names=[task_name],\n",
    "        bert_model=bert_model,\n",
    "        split_prop=0.8,\n",
    "        max_len=max_len,\n",
    "        dl_kwargs={\"batch_size\": 1},\n",
    "        bert_output_dim=bert_output_dim,\n",
    "        max_datapoints=10,\n",
    "    )\n",
    "\n",
    "model = MetalModel(tasks, verbose=False, device=-1)\n",
    "model.load_state_dict(torch.load(model_path)['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DataFrame of Predictions and True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  4.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'sentence1': [],\n",
    "    'sentence2': [],\n",
    "    'label': [],\n",
    "    'score' : []\n",
    "}\n",
    "max_batches = 100\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
    "from tqdm import tqdm\n",
    "count = 0\n",
    "for x, y in tqdm(list(dev_dl)):\n",
    "    for tokens_idx in x[0]:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokens_idx.numpy())\n",
    "        phrases = ' '.join(tokens).replace('[PAD]', '').replace('[CLS]', '').split('[SEP]')\n",
    "        data['sentence1'] += [phrases[0]]\n",
    "        if len(phrases) > 1:\n",
    "            data['sentence2'] += [phrases[1]] \n",
    "        else:\n",
    "            data['sentence2'] += ['NA']\n",
    "    scores = model.calculate_output(x, [task_name])[task_name].detach().cpu().numpy()[:, 0] # .flatten()\n",
    "    data['score'] += list(scores)\n",
    "    data['label'] += list(convert_labels(y, 'categorical', 'onezero').numpy())\n",
    "    count += 1\n",
    "    if count > max_batches:\n",
    "        break\n",
    "        \n",
    "\n",
    "df_error = pd.DataFrame(data, columns=['sentence1', 'sentence2', 'score', 'label'])\n",
    "df_error['pred'] = 1* (df_error.score > 0.5)\n",
    "df_error['is_wrong'] = df_error['pred'] != df_error['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Error DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe to:  /dfs/scratch0/jdunnmon/mmtl/sota_quest/debugging/RTE/dev_error_analysis.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dana reeve , the widow of the actor christoph...</td>\n",
       "      <td>christopher reeve had an accident .</td>\n",
       "      <td>0.461119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yet , we now are discovering that antibiotics...</td>\n",
       "      <td>bacteria is winning the war against antibioti...</td>\n",
       "      <td>0.310028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cairo is now home to some 15 million people -...</td>\n",
       "      <td>15 million tonnes of rubbish are produced dai...</td>\n",
       "      <td>0.759440</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the ami ##sh community in pennsylvania , whic...</td>\n",
       "      <td>pennsylvania has the biggest ami ##sh communi...</td>\n",
       "      <td>0.316320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>security forces were on high alert after an e...</td>\n",
       "      <td>security forces were on high alert after a ca...</td>\n",
       "      <td>0.832552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          sentence1  \\\n",
       "0           0   dana reeve , the widow of the actor christoph...   \n",
       "1           1   yet , we now are discovering that antibiotics...   \n",
       "2           2   cairo is now home to some 15 million people -...   \n",
       "3           3   the ami ##sh community in pennsylvania , whic...   \n",
       "4           4   security forces were on high alert after an e...   \n",
       "\n",
       "                                           sentence2     score  label  pred  \\\n",
       "0               christopher reeve had an accident .   0.461119      0     0   \n",
       "1   bacteria is winning the war against antibioti...  0.310028      1     0   \n",
       "2   15 million tonnes of rubbish are produced dai...  0.759440      0     1   \n",
       "3   pennsylvania has the biggest ami ##sh communi...  0.316320      0     0   \n",
       "4   security forces were on high alert after a ca...  0.832552      1     1   \n",
       "\n",
       "   is_wrong  \n",
       "0     False  \n",
       "1      True  \n",
       "2      True  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_dataframe(df,filepath):\n",
    "    df.to_csv(filepath, sep='\\t')\n",
    "    print('Saved dataframe to: ', filepath)\n",
    "    \n",
    "def load_dataframe(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    return df\n",
    "\n",
    "filepath = f'{csv_path}/dev_error_analysis.tsv'\n",
    "save_dataframe(df_error,filepath)\n",
    "df_error = load_dataframe(filepath)\n",
    "df_error.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_random_pred(df):\n",
    "    row = df.iloc[np.random.randint(df.shape[0])]\n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINCORRECT PREDICTIONS\u001b[0;0m\n",
      "sentence1: \t wilson has , after all , produced all three offspring albums , including \" smash , \" the one that has astonished everybody by selling 1 million copies in four months , establishing the here ##to ##for ##e unknown group as the leader , with green day , of an unprecedented wave of commercial success for punk . \n",
      "sentence2: \t \" smash \" is the title of the third album of the offspring . \n",
      "score: \t0.7452\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t released in 1995 , tyson returned to boxing , winning the world boxing council title in 1996 . the same year , however , he lost to evan ##der holy ##field , and in a 1997 rematch bit holy ##field ' s ear , for which he was temporarily banned from boxing . \n",
      "sentence2: \t in 1996 mike tyson bit holy ##field ' s ear . \n",
      "score: \t0.7653\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t the massachusetts supreme judicial court has cleared the way for lesbian and gay couples in the state to marry , ruling that government attorneys \" failed to identify any constitutional ##ly adequate reason \" to deny them the right . \n",
      "sentence2: \t u . s . supreme court in favor of same - sex marriage \n",
      "score: \t0.3174\n",
      "label: \t1\n",
      "\n",
      "\u001b[1mCORRECT PREDICTIONS\u001b[0;0m\n",
      "sentence1: \t ae ##sch ##ylus was born in 525 bc , and spent his youth as a soldier in the athenian army . he wrote the persians when he was 53 years old , but it is his earliest surviving work . \n",
      "sentence2: \t \" the persians \" was written by ae ##sch ##ylus . \n",
      "score: \t0.8607\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t wal - mart stores has asked a us federal appeals court to review a judge ' s order app ##roving class - action status for a sex - discrimination lawsuit . \n",
      "sentence2: \t the judge approve ##s of sex - discrimination . \n",
      "score: \t0.2300\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t brown brushed off a threat made monday by his counterpart , foreign trade minister wu yi , that if china ' s effort to join the general agreement on tariffs and trade ( ga ##tt ) by the year ' s end is unsuccessful , beijing will no longer be bound by previous trade and economic commitments . \n",
      "sentence2: \t wu yi is the foreign trade minister of china . \n",
      "score: \t0.9077\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mINCORRECT PREDICTIONS\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_random_pred(df_error[df_error.is_wrong==True])\n",
    "    print()\n",
    "    \n",
    "print(\"\\033[1mCORRECT PREDICTIONS\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_random_pred(df_error[df_error.is_wrong==False])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox for Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. We want to look at examples that are \"barely\" wrong and \"barely\" right since we have hope for boosts here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_barely_wrong_pred(df,thresh=0.05):\n",
    "    df_temp = df[df.is_wrong==True]\n",
    "    idx = np.where(np.abs(df_temp.score - 0.5) <= thresh)[0]\n",
    "    row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')  \n",
    "    \n",
    "def print_barely_right_pred(df,thresh=0.05):\n",
    "    df_temp = df[df.is_wrong==False]\n",
    "    idx = np.where(np.abs(df_temp.score - 0.5) <= thresh)[0]\n",
    "    row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBARELY WRONG\u001b[0;0m\n",
      "sentence1: \t confident that those grading papers would understand answers written in text - speak , ha ##que stressed that in some exams , including english , text abbreviation ##s would be penal ##ized . \n",
      "sentence2: \t ha ##que wants to include english in some exams . \n",
      "score: \t0.5478\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t napkin ##s , invitations and plain old paper cost more than they did a month ago . \n",
      "sentence2: \t the cost of paper is rising . \n",
      "score: \t0.4550\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t capital punishment acts as a deter ##rent . \n",
      "sentence2: \t capital punishment is a deter ##rent to crime . \n",
      "score: \t0.4875\n",
      "label: \t1\n",
      "\n",
      "\u001b[1mBARELY RIGHT\u001b[0;0m\n",
      "sentence1: \t the memo , written by marc allen connell ##y ( who was general counsel to the funeral services commission at the time ) and sent to dick mc ##neil ( the bush - appointed chairman of the funeral commission ) , stated that connell ##y \" received information \" from texas state officials that two of the funeral commissioners worked for sci . \n",
      "sentence2: \t marc allen connell ##y worked for sci . \n",
      "score: \t0.4611\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t dana reeve , the widow of the actor christopher reeve , has died of lung cancer at age 44 , according to the christopher reeve foundation . \n",
      "sentence2: \t christopher reeve had an accident . \n",
      "score: \t0.4611\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t dana reeve , the widow of the actor christopher reeve , has died of lung cancer at age 44 , according to the christopher reeve foundation . \n",
      "sentence2: \t christopher reeve had an accident . \n",
      "score: \t0.4611\n",
      "label: \t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mBARELY WRONG\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_barely_wrong_pred(df_error)\n",
    "    print()\n",
    "    \n",
    "print(\"\\033[1mBARELY RIGHT\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_barely_right_pred(df_error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. We also want to look at examples we got completely wrong since that could point to a systematic bias in the data/model. It could also help us find examples in the dataset that are mislabeled by human annotators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_very_wrong_pred(df,thresh=0.95):\n",
    "    df_temp = df[df.is_wrong==True]\n",
    "    try:\n",
    "        idx = np.where(np.abs(df_temp.score - df_temp.label) >= thresh)[0]\n",
    "        row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    except:\n",
    "        print(\"Threshold too high, reducing by 0.05\")\n",
    "        idx = np.where(np.abs(df_temp.score - df_temp.label) >= thresh-0.05)[0]\n",
    "        row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVERY WRONG\u001b[0;0m\n",
      "Threshold too high, reducing by 0.05\n",
      "sentence1: \t ar ##lene blu ##m is a legendary trail ##bla ##zer by any measure . def ##ying the climbing establishment of the 1970s , she led the first teams of women on successful ascent ##s of mt . mckinley and anna ##pur ##na , and was the first american woman to attempt mt . everest . in her long , adventurous career , she has played a leading role in more than twenty expeditions and forged a place for women in the per ##ilo ##us arena of high - altitude mountain ##eering . \n",
      "sentence2: \t a woman succeeds in climbing everest solo . \n",
      "score: \t0.9125\n",
      "label: \t0\n",
      "\n",
      "Threshold too high, reducing by 0.05\n",
      "sentence1: \t ah ##ern , who was travelling to tokyo for an eu - japan summit yesterday , will consult with other eu leaders by telephone later this week in an effort to find an agreed candidate . \n",
      "sentence2: \t a summit between europe and japan is taking place in the japan ##ise capital . \n",
      "score: \t0.0663\n",
      "label: \t1\n",
      "\n",
      "Threshold too high, reducing by 0.05\n",
      "sentence1: \t it appears that the super - conducting mag ##lev system is technically ready to be used commercially as a very high - speed , large - capacity transportation system . \n",
      "sentence2: \t mag ##lev is commercially used . \n",
      "score: \t0.9154\n",
      "label: \t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mVERY WRONG\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_very_wrong_pred(df_error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. To find systematic errors, we can also look for correlations between certain features and the incorrectness a la Socratic**\n",
    "\n",
    "\n",
    "We can make this way more sophisticated by perhaps using embeddings instead of this simple [BoW featurization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a vector of correct/incorrect predictions\n",
    "y = 2*(np.array(df_error.is_wrong.astype(float))-0.5)\n",
    "\n",
    "#Create corpus by combining sentences\n",
    "combined = []\n",
    "for a,b in zip(np.array(df_error.sentence1),np.array(df_error.sentence2)):\n",
    "    combined.append(str(a)+str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/venv-mmtl/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create BoW featurization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = np.array(list(df_error.sentence1))\n",
    "vectorizer = CountVectorizer(ngram_range=(2,5), stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "#Run LR to find correlations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(penalty=\"l1\")\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 000\n",
      "holy field\n",
      "harry potter\n",
      "capital punishment\n",
      "old city\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.stem(np.sort(np.abs(lr_model.coef_)[0])[::-1][0:50])\n",
    "plt.title('Feature Coefficient')\n",
    "plt.xlabel('Top k Features')\n",
    "\n",
    "top_idx = np.argsort(np.abs(lr_model.coef_)[0])[::-1][0:50]\n",
    "names = vectorizer.get_feature_names()\n",
    "for i in range(5):\n",
    "    print (names[top_idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSYSTEMATIC EXAMPLES\u001b[0;0m\n",
      "sentence1: \t cairo is now home to some 15 million people - a bu ##rgeon ##ing population that produces approximately 10 , 000 tonnes of rubbish per day , putting an enormous strain on public services . in the past 10 years , the government has tried hard to encourage private investment in the refuse sector , but some estimate 4 , 000 tonnes of waste is left behind every day , fest ##ering in the heat as it waits for someone to clear it up . it is often the people in the poor ##est neighbourhoods that are worst affected . but in some areas they are fighting back . in shu ##bra , one of the northern districts of the city , the residents have taken to the streets armed with dust ##pan ##s and brushes to clean up public areas which have been used as public dump ##s . \n",
      "sentence2: \t 15 million tonnes of rubbish are produced daily in cairo . \n",
      "score: \t0.7594\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t the town is also home to the dalai lama and to more than 10 , 000 tibetan ##s living in exile . \n",
      "sentence2: \t the dalai lama has been living in exile since 10 , 000 . \n",
      "score: \t0.7446\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t despite b ##jo ##rk making her first live performance in two years , the crowd of 10 , 000 people was only half of what the hall in the tokyo suburb of ma ##ku ##hari could hold . \n",
      "sentence2: \t 10 , 000 people live in tokyo . \n",
      "score: \t0.7904\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t capital punishment acts as a deter ##rent . \n",
      "sentence2: \t capital punishment is a deter ##rent to crime . \n",
      "score: \t0.4875\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t the kota ( \" fort \" ) , or old city , for example , sometimes called the downtown section , is the central business district and indonesia ' s financial capital . \n",
      "sentence2: \t the kota is the country ' s business center . \n",
      "score: \t0.4077\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t some of the buildings around the city square in the kota also date from colonial times , including the old city hall ( 1710 ) , which has been restored and now serves as the municipal museum . \n",
      "sentence2: \t the city hall is a museum now . \n",
      "score: \t0.4030\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mSYSTEMATIC EXAMPLES\\033[0;0m\")\n",
    "for i in range(5):\n",
    "    idx = list(np.where(X.todense()[:,top_idx[i]] == 1)[0])\n",
    "    for ii in range(len(idx)):\n",
    "        df_temp = df_error\n",
    "        row = df_temp.iloc[idx[ii]]\n",
    "\n",
    "        print(f'sentence1: \\t{row.sentence1}')\n",
    "        print(f'sentence2: \\t{row.sentence2}')\n",
    "        print('score: \\t{:.4f}'.format(row.score))    \n",
    "        print(f'label: \\t{row.label}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
