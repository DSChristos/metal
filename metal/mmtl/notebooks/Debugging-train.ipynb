{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "import metal.mmtl.dataset as dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from metal.mmtl.bert_tasks import create_tasks\n",
    "from metal.mmtl.metal_model import MetalModel\n",
    "from metal.mmtl.scorer import Scorer\n",
    "from metal.utils import convert_labels\n",
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/dfs/scratch0/jdunnmon/mmtl/sota_quest/debugging/COLA/COLA_19_48_08/best_model.pth'\n",
    "csv_path = \"/\".join(model_path.split('/')[0:-2]) #set to -1 if permissions exist\n",
    "task_name = model_path.split('/')[-3]\n",
    "\n",
    "bert_model = 'bert-base-uncased'\n",
    "max_len = 256\n",
    "bert_output_dim = 768\n",
    "dl_kwargs = {\"batch_size\": 32, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049253f1132641ebb5e62b75f8f4c558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading COLA Dataset\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7edd4101d5341b48142bd093f820f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08acd98ceea843e097214121207dba0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Get DataLoader\n",
    "dataset_cls = getattr(dataset, task_name.upper() + \"Dataset\")\n",
    "dev_ds = dataset_cls(\n",
    "    split=\"train\",\n",
    "    bert_model=bert_model,\n",
    "    max_len=max_len,\n",
    "    max_datapoints=-1,\n",
    ")\n",
    "dev_dl = dev_ds.get_dataloader(**dl_kwargs)\n",
    "\n",
    "#Load best model for specified task\n",
    "tasks = create_tasks(\n",
    "        task_names=[task_name],\n",
    "        bert_model=bert_model,\n",
    "        split_prop=0.8,\n",
    "        max_len=max_len,\n",
    "        dl_kwargs={\"batch_size\": 1},\n",
    "        bert_output_dim=bert_output_dim,\n",
    "        max_datapoints=10,\n",
    "    )\n",
    "\n",
    "model = MetalModel(tasks, verbose=False, device=-1)\n",
    "model.load_state_dict(torch.load(model_path)['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DataFrame of Predictions and True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 96/268 [00:03<00:03, 43.71it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'sentence1': [],\n",
    "    'sentence2': [],\n",
    "    'label': [],\n",
    "    'score' : []\n",
    "}\n",
    "max_batches = 100\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
    "from tqdm import tqdm\n",
    "count = 0\n",
    "for x, y in tqdm(list(dev_dl)):\n",
    "    for tokens_idx in x[0]:\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokens_idx.numpy())\n",
    "        phrases = ' '.join(tokens).replace('[PAD]', '').replace('[CLS]', '').split('[SEP]')\n",
    "        data['sentence1'] += [phrases[0]]\n",
    "        if len(phrases) > 1:\n",
    "            data['sentence2'] += [phrases[1]] \n",
    "        else:\n",
    "            data['sentence2'] += ['NA']\n",
    "    scores = model.calculate_output(x, [task_name])[task_name].detach().cpu().numpy()[:, 0] # .flatten()\n",
    "    data['score'] += list(scores)\n",
    "    data['label'] += list(convert_labels(y, 'categorical', 'onezero').numpy())\n",
    "    count += 1\n",
    "    if count > max_batches:\n",
    "        break\n",
    "        \n",
    "\n",
    "df_error = pd.DataFrame(data, columns=['sentence1', 'sentence2', 'score', 'label'])\n",
    "df_error['pred'] = 1* (df_error.score > 0.5)\n",
    "df_error['is_wrong'] = df_error['pred'] != df_error['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Error DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataframe to:  /dfs/scratch0/jdunnmon/mmtl/sota_quest/debugging/COLA/train_error_analysis.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>our friends won ' t buy this analysis , let a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989495</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>one more pseudo general ##ization and i ' m g...</td>\n",
       "      <td></td>\n",
       "      <td>0.994083</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>one more pseudo general ##ization or i ' m gi...</td>\n",
       "      <td></td>\n",
       "      <td>0.990415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the more we study verbs , the cr ##azi ##er t...</td>\n",
       "      <td></td>\n",
       "      <td>0.989520</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>day by day the facts are getting mu ##rk ##ie...</td>\n",
       "      <td></td>\n",
       "      <td>0.990852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          sentence1 sentence2  \\\n",
       "0           0   our friends won ' t buy this analysis , let a...       NaN   \n",
       "1           1   one more pseudo general ##ization and i ' m g...             \n",
       "2           2   one more pseudo general ##ization or i ' m gi...             \n",
       "3           3   the more we study verbs , the cr ##azi ##er t...             \n",
       "4           4   day by day the facts are getting mu ##rk ##ie...             \n",
       "\n",
       "      score  label  pred  is_wrong  \n",
       "0  0.989495      1     1     False  \n",
       "1  0.994083      1     1     False  \n",
       "2  0.990415      1     1     False  \n",
       "3  0.989520      1     1     False  \n",
       "4  0.990852      1     1     False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_dataframe(df,filepath):\n",
    "    df.to_csv(filepath, sep='\\t')\n",
    "    print('Saved dataframe to: ', filepath)\n",
    "    \n",
    "def load_dataframe(filepath):\n",
    "    df = pd.read_csv(filepath, sep='\\t')\n",
    "    return df\n",
    "\n",
    "filepath = f'{csv_path}/train_error_analysis.tsv'\n",
    "save_dataframe(df_error,filepath)\n",
    "df_error = load_dataframe(filepath)\n",
    "df_error.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_random_pred(df):\n",
    "    row = df.iloc[np.random.randint(df.shape[0])]\n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINCORRECT PREDICTIONS\u001b[0;0m\n",
      "sentence1: \t reports of which the government pre ##scribe ##s the height of the lettering on the covers are invariably boring . \n",
      "sentence2: \t        \n",
      "score: \t0.9027\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t that he ever went there alone is certain . \n",
      "sentence2: \t           \n",
      "score: \t0.9547\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i brought john a razor with which to shave myself . \n",
      "sentence2: \t            \n",
      "score: \t0.9794\n",
      "label: \t0\n",
      "\n",
      "\u001b[1mCORRECT PREDICTIONS\u001b[0;0m\n",
      "sentence1: \t the dog barked out of the room . \n",
      "sentence2: \t   \n",
      "score: \t0.0203\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t sam got free by cutting his finger . \n",
      "sentence2: \t          \n",
      "score: \t0.9922\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t maxwell isn ' t half the doctor that people around here believe that his father was . \n",
      "sentence2: \t         \n",
      "score: \t0.9375\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mINCORRECT PREDICTIONS\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_random_pred(df_error[df_error.is_wrong==True])\n",
    "    print()\n",
    "    \n",
    "print(\"\\033[1mCORRECT PREDICTIONS\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_random_pred(df_error[df_error.is_wrong==False])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox for Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. We want to look at examples that are \"barely\" wrong and \"barely\" right since we have hope for boosts here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_barely_wrong_pred(df,thresh=0.05):\n",
    "    df_temp = df[df.is_wrong==True]\n",
    "    idx = np.where(np.abs(df_temp.score - 0.5) <= thresh)[0]\n",
    "    row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')  \n",
    "    \n",
    "def print_barely_right_pred(df,thresh=0.05):\n",
    "    df_temp = df[df.is_wrong==False]\n",
    "    idx = np.where(np.abs(df_temp.score - 0.5) <= thresh)[0]\n",
    "    row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBARELY WRONG\u001b[0;0m\n",
      "sentence1: \t you get ang ##rier , the more we eat , don ' t we . \n",
      "sentence2: \t    \n",
      "score: \t0.5404\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t ba ##ke for 30 minutes . \n",
      "sentence2: \t      \n",
      "score: \t0.4801\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t john wage ##red a stranger to have been in that haunted house . \n",
      "sentence2: \t \n",
      "score: \t0.5047\n",
      "label: \t0\n",
      "\n",
      "\u001b[1mBARELY RIGHT\u001b[0;0m\n",
      "sentence1: \t the hot potato had several hundred people yelling for me to put it down gently . \n",
      "sentence2: \t         \n",
      "score: \t0.4580\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t lilly recounted a story to be remembered because holly had recounted a story to be . \n",
      "sentence2: \t              \n",
      "score: \t0.4944\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t john wrote books . \n",
      "sentence2: \t        \n",
      "score: \t0.4628\n",
      "label: \t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mBARELY WRONG\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_barely_wrong_pred(df_error)\n",
    "    print()\n",
    "    \n",
    "print(\"\\033[1mBARELY RIGHT\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_barely_right_pred(df_error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. We also want to look at examples we got completely wrong since that could point to a systematic bias in the data/model. It could also help us find examples in the dataset that are mislabeled by human annotators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_very_wrong_pred(df,thresh=0.95):\n",
    "    df_temp = df[df.is_wrong==True]\n",
    "    try:\n",
    "        idx = np.where(np.abs(df_temp.score - df_temp.label) >= thresh)[0]\n",
    "        row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    except:\n",
    "        print(\"Threshold too high, reducing by 0.05\")\n",
    "        idx = np.where(np.abs(df_temp.score - df_temp.label) >= thresh-0.05)[0]\n",
    "        row = df_temp.iloc[np.random.choice(list(idx))]\n",
    "    \n",
    "    print(f'sentence1: \\t{row.sentence1}')\n",
    "    print(f'sentence2: \\t{row.sentence2}')\n",
    "    print('score: \\t{:.4f}'.format(row.score))    \n",
    "    print(f'label: \\t{row.label}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVERY WRONG\u001b[0;0m\n",
      "sentence1: \t ellen said to helen . \n",
      "sentence2: \t      \n",
      "score: \t0.9667\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i didn ' t give jack this picture of anybody . \n",
      "sentence2: \t           \n",
      "score: \t0.9547\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t the horse broke penny in the shin . \n",
      "sentence2: \t  \n",
      "score: \t0.9836\n",
      "label: \t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mVERY WRONG\\033[0;0m\")\n",
    "for i in range(3):\n",
    "    print_very_wrong_pred(df_error)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. To find systematic errors, we can also look for correlations between certain features and the incorrectness a la Socratic**\n",
    "\n",
    "\n",
    "We can make this way more sophisticated by perhaps using embeddings instead of this simple [BoW featurization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/venv-mmtl/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a vector of correct/incorrect predictions\n",
    "y = 2*(np.array(df_error.is_wrong.astype(float))-0.5)\n",
    "\n",
    "#Create corpus by combining sentences\n",
    "combined = []\n",
    "for a,b in zip(np.array(df_error.sentence1),np.array(df_error.sentence2)):\n",
    "    combined.append(str(a)+str(b))\n",
    "\n",
    "#Create BoW featurization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = np.array(list(df_error.sentence1))\n",
    "vectorizer = CountVectorizer(ngram_range=(2,5), stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "#Run LR to find correlations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(penalty=\"l1\")\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm roger eaten\n",
      "senator corrupt\n",
      "boy guardian employer\n",
      "john hero\n",
      "man john\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.stem(np.sort(np.abs(lr_model.coef_)[0])[::-1][0:50])\n",
    "plt.title('Feature Coefficient')\n",
    "plt.xlabel('Top k Features')\n",
    "\n",
    "top_idx = np.argsort(np.abs(lr_model.coef_)[0])[::-1][0:50]\n",
    "names = vectorizer.get_feature_names()\n",
    "for i in range(5):\n",
    "    print (names[top_idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSYSTEMATIC EXAMPLES\u001b[0;0m\n",
      "sentence1: \t what did bill confirm that roger had eaten ? \n",
      "sentence2: \t                                    \n",
      "score: \t0.9561\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t bill didn ' t confirm that roger had eaten anything . \n",
      "sentence2: \t                                  \n",
      "score: \t0.9884\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t every senator becomes more corrupt , the more lobby ##ists he talks to . \n",
      "sentence2: \t         \n",
      "score: \t0.9905\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t any senator becomes more corrupt , the more lobby ##ists he talks to . \n",
      "sentence2: \t         \n",
      "score: \t0.4490\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t every senator seems to become more corrupt , if he talks to more lobby ##ists . \n",
      "sentence2: \t       \n",
      "score: \t0.8101\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t any senator seems to become more corrupt , if he talks to more lobby ##ists . \n",
      "sentence2: \t       \n",
      "score: \t0.3520\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t any senator seems to become more corrupt , as he talks to more lobby ##ists . \n",
      "sentence2: \t       \n",
      "score: \t0.1878\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t we elected president the boy ' s guardian ' s employer . \n",
      "sentence2: \t                \n",
      "score: \t0.0211\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t which boy ' s guardian ' s employer did we elect president ? . \n",
      "sentence2: \t              \n",
      "score: \t0.1476\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t we proclaimed to the public john to be a hero . \n",
      "sentence2: \t   \n",
      "score: \t0.7166\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t we proclaimed sincerely john to be a hero . \n",
      "sentence2: \t     \n",
      "score: \t0.5095\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t we proclaimed sincerely to the public john to be a hero . \n",
      "sentence2: \t  \n",
      "score: \t0.2487\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i know a man who john is taller than is . \n",
      "sentence2: \t                 \n",
      "score: \t0.6501\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i know a man who john is as tall as is . \n",
      "sentence2: \t                \n",
      "score: \t0.6097\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t i know a man who john is as tall as . \n",
      "sentence2: \t                 \n",
      "score: \t0.9921\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t mary has never kissed as tall a man as john is . \n",
      "sentence2: \t                \n",
      "score: \t0.5432\n",
      "label: \t0\n",
      "\n",
      "sentence1: \t mary has never kissed as tall a man as john . \n",
      "sentence2: \t                 \n",
      "score: \t0.6099\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t i know a taller man than john . \n",
      "sentence2: \t                    \n",
      "score: \t0.9945\n",
      "label: \t1\n",
      "\n",
      "sentence1: \t he told peter that i know a taller man than john , but peter didn ' t believe it . \n",
      "sentence2: \t       \n",
      "score: \t0.9917\n",
      "label: \t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1mSYSTEMATIC EXAMPLES\\033[0;0m\")\n",
    "for i in range(5):\n",
    "    idx = list(np.where(X.todense()[:,top_idx[i]] == 1)[0])\n",
    "    for ii in range(len(idx)):\n",
    "        df_temp = df_error\n",
    "        row = df_temp.iloc[idx[ii]]\n",
    "\n",
    "        print(f'sentence1: \\t{row.sentence1}')\n",
    "        print(f'sentence2: \\t{row.sentence2}')\n",
    "        print('score: \\t{:.4f}'.format(row.score))    \n",
    "        print(f'label: \\t{row.label}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
