{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from metal.end_model import EndModel\n",
    "from metal.mmtl.utils.dataset_utils import get_all_dataloaders\n",
    "from metal.mmtl.dataset import QNLIDataset\n",
    "from metal.mmtl.modules import BertEncoder\n",
    "from metal.mmtl.metal_model import MetalModel\n",
    "from metal.mmtl.scorer import Scorer\n",
    "from metal.mmtl.task import Task\n",
    "from metal.mmtl.trainer import MultitaskTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = 'bert-base-uncased'\n",
    "bert_model_output_shape = 768\n",
    "max_len = 512\n",
    "batch_size = 16\n",
    "split_prop = 0.8\n",
    "trainer_config = {\n",
    "    \"verbose\": True,\n",
    "    \"device\": \"cuda\",\n",
    "    \"loss_fn_reduction\": \"mean\",\n",
    "    \"progress_bar\": True,\n",
    "    #\"data_loader_config\": {\"batch_size\": 32, \"num_workers\": 1, \"shuffle\": True}, ## TODO? \n",
    "    \"n_epochs\": 1,\n",
    "    # 'grad_clip': 1.0,  ## TODO? \n",
    "    \"l2\": 0.01,\n",
    "    \"optimizer_config\": {\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"optimizer_common\": {\"lr\": 1e-5},\n",
    "        \"adam_config\": {\"betas\": (0.9, 0.999)},\n",
    "    },\n",
    "    \"lr_scheduler\": \"exponential\", # reduce_on_plateau  ## TODO? Warmup\n",
    "    \"lr_scheduler_config\": {\n",
    "        \"lr_freeze\": 0,\n",
    "        # Scheduler - exponential\n",
    "        \"exponential_config\": {\"gamma\": 0.9},  # decay rate\n",
    "        # Scheduler - reduce_on_plateau\n",
    "        \"plateau_config\": {\n",
    "            \"factor\": 0.5,\n",
    "            \"patience\": 10,\n",
    "            \"threshold\": 0.0001,\n",
    "            \"min_lr\": 1e-4,\n",
    "        },\n",
    "    },\n",
    "    # Logger (see metal/logging/logger.py for descriptions)\n",
    "    \"logger\": True,\n",
    "    \"logger_config\": {\n",
    "        \"log_unit\": \"epochs\",  # ['seconds', 'examples', 'batches', 'epochs']\n",
    "        \"log_every\": 0.05,\n",
    "        \"score_every\": 0.1,\n",
    "    },# Checkpointer (see metal/logging/checkpointer.py for descriptions)\n",
    "    \"checkpoint\": True,  # If True, checkpoint models when certain conditions are met\n",
    "    \"checkpoint_config\": {\n",
    "        \"checkpoint_every\": 0,  # Save a model checkpoint every this many log_units\n",
    "        \"checkpoint_best\": True,\n",
    "        # \"checkpoint_final\": False,  # Save a model checkpoint at the end of training\n",
    "        \"checkpoint_metric\": \"ranking/valid/accuracy\",\n",
    "        \"checkpoint_metric_mode\": \"max\",\n",
    "        \"checkpoint_dir\": f\"{os.environ['METALHOME']}/checkpoints/qnli_single\",\n",
    "        \"checkpoint_runway\": 0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5463/5463 [00:04<00:00, 1224.48it/s]\n",
      "100%|██████████| 5463/5463 [00:04<00:00, 1234.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#dataloaders = get_all_dataloaders(\n",
    "#    \"QNLI\", bert_model,\n",
    "#    train_dev_split_prop=split_prop,\n",
    "#    max_len=max_len\n",
    "#)\n",
    "dataloaders = {}\n",
    "for split in ['test', 'dev']:\n",
    "    dataset = QNLIDataset(\n",
    "        split=split,\n",
    "        bert_model=bert_model,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    dataloaders[split] = dataset.get_dataloader(batch_size=batch_size, shuffle=True)\n",
    "dataloaders['train'] = dataloaders['dev']\n",
    "dataloaders['valid'] = dataloaders['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encoder = BertEncoder(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, List\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ranking_head = nn.Linear(in_features=bert_model_output_shape, out_features=2, bias=False)\n",
    "ranking_task = Task(\n",
    "    name=\"ranking\",\n",
    "    data_loaders=dataloaders, \n",
    "    input_module=bert_encoder,\n",
    "    head_module=ranking_head,\n",
    "    scorer=Scorer(standard_metrics=[\"accuracy\"]),\n",
    "    loss_hat_func= lambda X, Y: F.cross_entropy(X, Y - 1),\n",
    "    output_hat_func=partial(F.softmax, dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9500738d7a55417499fc3b75d1bd797f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=342), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.050521691378363535 epo]: TRAIN:[loss=0.641]\n",
      "{'ranking/loss': 0.6414394093596417, 'train/loss': 0.6414394093596417}\n",
      "ranking/valid/accuracy\n",
      "[0.10104338275672707 epo]: TRAIN:[loss=0.523] VALID:[ranking/accuracy=0.813]\n",
      "{'ranking/loss': 0.5226242652405864, 'train/loss': 0.5226242652405864, 'ranking/valid/accuracy': 0.8125572030020135}\n",
      "ranking/valid/accuracy\n",
      "hello\n",
      "Saving model at iteration 0.10104338275672707 with best (max) score 0.813\n",
      "[0.1515650741350906 epo]: TRAIN:[loss=0.466]\n",
      "{'ranking/loss': 0.46633189868019975, 'train/loss': 0.46633189868019975}\n",
      "ranking/valid/accuracy\n",
      "\n",
      "Restoring best model from iteration 0.10104338275672707 with score 0.813\n",
      "Finished Training\n",
      "{'ranking/valid/accuracy': 0.8125572030020135}\n"
     ]
    }
   ],
   "source": [
    "tasks = [ranking_task]\n",
    "model = MetalModel(tasks, verbose=False)\n",
    "trainer = MultitaskTrainer()\n",
    "trainer.train_model(\n",
    "    model,\n",
    "    tasks,\n",
    "    **trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ranking': tensor([[ 0.3899, -0.5400],\n",
      "        [ 0.4240, -0.5404],\n",
      "        [ 0.3580, -0.6234],\n",
      "        [ 0.4644, -0.6587],\n",
      "        [-0.8041,  1.6927],\n",
      "        [-0.4173,  0.9388],\n",
      "        [-0.3887,  0.4791],\n",
      "        [ 0.4736, -0.7310],\n",
      "        [-0.5424,  0.5344],\n",
      "        [-0.2840,  1.0988],\n",
      "        [-0.3985,  0.9711],\n",
      "        [-0.5806,  1.2527],\n",
      "        [ 0.7220, -0.9857],\n",
      "        [ 0.2798, -0.3332],\n",
      "        [ 0.3106, -0.4223],\n",
      "        [-0.4811,  1.6733]], device='cuda:0', grad_fn=<MmBackward>)}\n",
      "{'ranking': tensor(0.3953, device='cuda:0', grad_fn=<NllLossBackward>)}\n",
      "{'ranking': tensor([[0.7171, 0.2829],\n",
      "        [0.7240, 0.2760],\n",
      "        [0.7274, 0.2726],\n",
      "        [0.7546, 0.2454],\n",
      "        [0.0761, 0.9239],\n",
      "        [0.2049, 0.7951],\n",
      "        [0.2957, 0.7043],\n",
      "        [0.7693, 0.2307],\n",
      "        [0.2541, 0.7459],\n",
      "        [0.2006, 0.7994],\n",
      "        [0.2027, 0.7973],\n",
      "        [0.1378, 0.8622],\n",
      "        [0.8465, 0.1535],\n",
      "        [0.6486, 0.3514],\n",
      "        [0.6754, 0.3246],\n",
      "        [0.1039, 0.8961]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for (X, Y) in dataloaders['dev']:\n",
    "    X = [x.cuda() for x in X]\n",
    "    print(model(X, ['ranking']))\n",
    "    print(model.calculate_loss(X, Y.cuda(), ['ranking']))    \n",
    "    print(model.calculate_output(X, ['ranking']))    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(metal)",
   "language": "python",
   "name": "metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
