{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_names = [\n",
    "    \"COLA\", \n",
    "#     \"SST2\",\n",
    "#     \"MNLI\",\n",
    "#     \"RTE\",\n",
    "#     \"WNLI\",\n",
    "#     \"QQP\",\n",
    "#     \"MRPC\",\n",
    "#     \"STSB\",\n",
    "#     \"QNLI\",\n",
    "#     \"SPACY_POS\",\n",
    "#     \"SPACY_NER\",\n",
    "#     \"THIRD\",\n",
    "#     \"BLEU\",\n",
    "]\n",
    "\n",
    "FILENAME = \"COLA_tasks_and_payloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously trained model\n",
    "Hint: make sure the `bert_model` is initialized correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed: 590343\n",
      "Loading COLA Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0b0659c6904c9dbac7d1afc3d34bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc466da28f9446b3a346e9bd8eda47fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1043), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255724b3c7724659975844365e3d9925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1063), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 26.7 s, sys: 7.35 s, total: 34 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from metal.mmtl.glue.glue_tasks import create_tasks_and_payloads\n",
    "\n",
    "# Create tasks and payloads\n",
    "tasks, payloads = create_tasks_and_payloads(\n",
    "    task_names,\n",
    "    dl_kwargs={\"batch_size\": 16},\n",
    "#     freeze_bert=True,\n",
    "    bert_model='bert-large-cased'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ClassificationTask(name=COLA, loss_multiplier=1.0)],\n",
       " [Payload(COLA_train: tasks=[COLA], split=train),\n",
       "  Payload(COLA_valid: tasks=[COLA], split=valid),\n",
       "  Payload(COLA_test: tasks=[COLA], split=test)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks, payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.mmtl.metal_model import MetalModel\n",
    "\n",
    "model = MetalModel(tasks, seed=SEED, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "model_dir = '/dfs/scratch0/chami/metal/metal/mmtl/aws/output/2019_03_14_01_58_14/0/logdir/bert_large/QNLI.STSB.MRPC.QQP.RTE.MNLI.SST2.COLA.WNLI_09_15_09'\n",
    "model_path = os.path.join(model_dir, 'best_model.pth')\n",
    "device = torch.device(f\"cuda:0\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=device)[\"model\"], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check that task head is trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COLA/COLA_valid/accuracy': 0.8465963566634708,\n",
       " 'COLA/COLA_valid/matthews_corr': 0.6313245338647664}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(payloads[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define slices for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed: 128037\n",
      "Loading COLA Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ede741e04146049af4072119411f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ba38e98f3f49e1b6ccd0d18ce668b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1043), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde6350a506743c8ba0e11097cbd09cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1063), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added label_set with 8551 labels for task COLA:ends_with_question_mark to payload COLA_train.\n",
      "Added label_set with 1043 labels for task COLA:ends_with_question_mark to payload COLA_valid.\n",
      "Added label_set with 1063 labels for task COLA:ends_with_question_mark to payload COLA_test.\n",
      "CPU times: user 21.5 s, sys: 7.13 s, total: 28.6 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from metal.mmtl.glue.glue_tasks import create_tasks_and_payloads\n",
    "\n",
    "# define slices\n",
    "slice_dict = {  # A map of the slices that apply to each task\n",
    "   \"COLA\": [\"ends_with_question_mark\"]\n",
    "}\n",
    "\n",
    "# Create tasks and payloads\n",
    "_, payloads_slice = create_tasks_and_payloads(\n",
    "    task_names,\n",
    "    dl_kwargs={\"batch_size\": 16},\n",
    "    slice_dict=slice_dict,\n",
    "#     freeze_bert=True,\n",
    "    bert_model='bert-large-cased'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Payload(COLA_train: tasks=[COLA,COLA:ends_with_question_mark], split=train),\n",
       " Payload(COLA_valid: tasks=[COLA,COLA:ends_with_question_mark], split=valid),\n",
       " Payload(COLA_test: tasks=[COLA,COLA:ends_with_question_mark], split=test)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payloads_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check the number of examples in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def count_num_labels(labels):\n",
    "    return np.sum(np.array(labels) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLA 8551\n",
      "COLA:ends_with_question_mark 615\n"
     ]
    }
   ],
   "source": [
    "dataset = payloads_slice[0].data_loader.dataset\n",
    "for labelset_name, labels in dataset.labels.items():\n",
    "    print(labelset_name, count_num_labels(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate baseline model on the slice of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 57 / 1043 active labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'COLA/COLA_valid/accuracy': 0.8465963566634708,\n",
       " 'COLA/COLA_valid/matthews_corr': 0.6313245338647664,\n",
       " 'COLA:ends_with_question_mark/COLA_valid/accuracy': 0.7543859649122807,\n",
       " 'COLA:ends_with_question_mark/COLA_valid/matthews_corr': 0.4818181818181818}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(payloads_slice[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune model on slice of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from metal.mmtl.metal_model import MetalModel\n",
    "\n",
    "from metal.mmtl.trainer import MultitaskTrainer\n",
    "trainer = MultitaskTrainer(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only finetune on the slices, not the original task\n",
    "# for p in payloads_slice:\n",
    "#     p.task_names.remove('COLA')\n",
    "# payloads_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We are training on a different set of payloads than we initialized the model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning train loop.\n",
      "Expecting a total of approximately 8560 examples and 535 batches per epoch from 1 payload(s) in the train split.\n",
      "Writing config to /dfs/scratch0/vschen/metal-mmtl/logs/2019_03_17/20_39_08/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/metal-mmtl/metal/mmtl/trainer.py:578: UserWarning: checkpoint_tasks setting does not have the same thorough error checking that the normal checkpoint operation has, so you may accidentally be trying to checkpoint metrics that aren't going to be found in the metrics_dict if you're not careful.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22520d134b14b988cf78817ec9196db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=535), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05 epo]: COLA:[train/loss=2.20e-01] COLA:ends_with_question_mark:[train/loss=2.75e-01] model:[train/loss=2.24e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.10 epo]: COLA:[train/loss=3.46e-01, COLA_valid/accuracy=8.35e-01, COLA_valid/matthews_corr=5.96e-01] COLA:ends_with_question_mark:[train/loss=4.73e-01, COLA_valid/accuracy=6.84e-01, COLA_valid/matthews_corr=3.07e-01] model:[train/loss=3.55e-01, train/lr=3.00e-05, valid/glue=5.96e-01]\n",
      "Saving model at iteration 0.10 with best (max) score COLA/COLA_valid/matthews_corr=0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/metal-mmtl/metal/mmtl/trainer.py:489: UserWarning: You requested glue score but have fewer than 9 tasks. Be aware.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at iteration 0.10 with best (max) score COLA:ends_with_question_mark/COLA_valid/matthews_corr=0.307\n",
      "[0.15 epo]: COLA:[train/loss=2.53e-01] COLA:ends_with_question_mark:[train/loss=4.18e-01] model:[train/loss=2.69e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.20 epo]: COLA:[train/loss=3.48e-01, COLA_valid/accuracy=8.43e-01, COLA_valid/matthews_corr=6.22e-01] COLA:ends_with_question_mark:[train/loss=3.26e-01, COLA_valid/accuracy=7.37e-01, COLA_valid/matthews_corr=4.40e-01] model:[train/loss=3.47e-01, train/lr=3.00e-05, valid/glue=6.22e-01]\n",
      "Saving model at iteration 0.20 with best (max) score COLA/COLA_valid/matthews_corr=0.622\n",
      "Saving model at iteration 0.20 with best (max) score COLA:ends_with_question_mark/COLA_valid/matthews_corr=0.440\n",
      "[0.25 epo]: COLA:[train/loss=3.61e-01] COLA:ends_with_question_mark:[train/loss=6.54e-01] model:[train/loss=3.81e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.30 epo]: COLA:[train/loss=2.12e-01, COLA_valid/accuracy=8.31e-01, COLA_valid/matthews_corr=5.86e-01] COLA:ends_with_question_mark:[train/loss=1.53e-01, COLA_valid/accuracy=7.02e-01, COLA_valid/matthews_corr=3.42e-01] model:[train/loss=2.08e-01, train/lr=3.00e-05, valid/glue=5.86e-01]\n",
      "[0.35 epo]: COLA:[train/loss=2.64e-01] COLA:ends_with_question_mark:[train/loss=2.43e-01] model:[train/loss=2.63e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.40 epo]: COLA:[train/loss=2.77e-01, COLA_valid/accuracy=8.29e-01, COLA_valid/matthews_corr=5.81e-01] COLA:ends_with_question_mark:[train/loss=3.38e-01, COLA_valid/accuracy=7.19e-01, COLA_valid/matthews_corr=3.99e-01] model:[train/loss=2.81e-01, train/lr=3.00e-05, valid/glue=5.81e-01]\n",
      "[0.45 epo]: COLA:[train/loss=3.29e-01] COLA:ends_with_question_mark:[train/loss=4.70e-01] model:[train/loss=3.39e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.50 epo]: COLA:[train/loss=2.50e-01, COLA_valid/accuracy=8.16e-01, COLA_valid/matthews_corr=5.45e-01] COLA:ends_with_question_mark:[train/loss=5.86e-02, COLA_valid/accuracy=7.19e-01, COLA_valid/matthews_corr=3.86e-01] model:[train/loss=2.41e-01, train/lr=3.00e-05, valid/glue=5.45e-01]\n",
      "[0.56 epo]: COLA:[train/loss=2.83e-01] COLA:ends_with_question_mark:[train/loss=4.35e-01] model:[train/loss=2.95e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.61 epo]: COLA:[train/loss=2.55e-01, COLA_valid/accuracy=8.19e-01, COLA_valid/matthews_corr=5.54e-01] COLA:ends_with_question_mark:[train/loss=5.23e-01, COLA_valid/accuracy=7.37e-01, COLA_valid/matthews_corr=4.28e-01] model:[train/loss=2.73e-01, train/lr=3.00e-05, valid/glue=5.54e-01]\n",
      "[0.66 epo]: COLA:[train/loss=3.53e-01] COLA:ends_with_question_mark:[train/loss=8.02e-01] model:[train/loss=3.76e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.71 epo]: COLA:[train/loss=2.45e-01, COLA_valid/accuracy=8.37e-01, COLA_valid/matthews_corr=6.01e-01] COLA:ends_with_question_mark:[train/loss=4.01e-01, COLA_valid/accuracy=7.54e-01, COLA_valid/matthews_corr=4.74e-01] model:[train/loss=2.54e-01, train/lr=3.00e-05, valid/glue=6.01e-01]\n",
      "Saving model at iteration 0.71 with best (max) score COLA:ends_with_question_mark/COLA_valid/matthews_corr=0.474\n",
      "[0.76 epo]: COLA:[train/loss=2.39e-01] COLA:ends_with_question_mark:[train/loss=1.42e-01] model:[train/loss=2.32e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.81 epo]: COLA:[train/loss=3.38e-01, COLA_valid/accuracy=8.37e-01, COLA_valid/matthews_corr=6.02e-01] COLA:ends_with_question_mark:[train/loss=4.48e-01, COLA_valid/accuracy=7.54e-01, COLA_valid/matthews_corr=4.69e-01] model:[train/loss=3.46e-01, train/lr=3.00e-05, valid/glue=6.02e-01]\n",
      "[0.86 epo]: COLA:[train/loss=2.25e-01] COLA:ends_with_question_mark:[train/loss=1.47e-01] model:[train/loss=2.20e-01, train/lr=3.00e-05]\n",
      "Evaluating 57 / 1043 active labels\n",
      "[0.91 epo]: COLA:[train/loss=2.23e-01, COLA_valid/accuracy=8.36e-01, COLA_valid/matthews_corr=5.99e-01] COLA:ends_with_question_mark:[train/loss=2.45e-01, COLA_valid/accuracy=7.37e-01, COLA_valid/matthews_corr=4.33e-01] model:[train/loss=2.25e-01, train/lr=3.00e-05, valid/glue=5.99e-01]\n",
      "[0.96 epo]: COLA:[train/loss=2.86e-01] COLA:ends_with_question_mark:[train/loss=2.28e-01] model:[train/loss=2.82e-01, train/lr=3.00e-05]\n",
      "\n",
      "Finished training\n",
      "Evaluating 615 / 8551 active labels\n",
      "Evaluating 57 / 1043 active labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/vschen/venv-mmtl/lib/python3.6/site-packages/sklearn/metrics/classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 53 / 1063 active labels\n",
      "{'COLA/COLA_test/accuracy': 0.0,\n",
      " 'COLA/COLA_test/matthews_corr': 0.0,\n",
      " 'COLA/COLA_train/accuracy': 0.9401239621096947,\n",
      " 'COLA/COLA_train/matthews_corr': 0.854402919502345,\n",
      " 'COLA/COLA_valid/accuracy': 0.8312559923298178,\n",
      " 'COLA/COLA_valid/matthews_corr': 0.5856531698367675,\n",
      " 'COLA:ends_with_question_mark/COLA_test/accuracy': 0.0,\n",
      " 'COLA:ends_with_question_mark/COLA_test/matthews_corr': 0.0,\n",
      " 'COLA:ends_with_question_mark/COLA_train/accuracy': 0.9252032520325203,\n",
      " 'COLA:ends_with_question_mark/COLA_train/matthews_corr': 0.8260685528009882,\n",
      " 'COLA:ends_with_question_mark/COLA_valid/accuracy': 0.7543859649122807,\n",
      " 'COLA:ends_with_question_mark/COLA_valid/matthews_corr': 0.4742657956547625,\n",
      " 'model/None/glue': 0.5856531698367675}\n",
      "Restoring best model from iteration 0.20 with score 0.622\n",
      "Restoring best model from iteration 0.71 with score 0.474\n",
      "Final scores using task-specific checkpoints:\n",
      "{'COLA/COLA_test/accuracy': 0.0,\n",
      " 'COLA/COLA_test/matthews_corr': 0.0,\n",
      " 'COLA/COLA_train/accuracy': 0.9401239621096947,\n",
      " 'COLA/COLA_train/matthews_corr': 0.854402919502345,\n",
      " 'COLA/COLA_valid/accuracy': 0.8312559923298178,\n",
      " 'COLA/COLA_valid/matthews_corr': 0.5856531698367675,\n",
      " 'COLA:ends_with_question_mark/COLA_test/accuracy': 0.0,\n",
      " 'COLA:ends_with_question_mark/COLA_test/matthews_corr': 0.0,\n",
      " 'COLA:ends_with_question_mark/COLA_train/accuracy': 0.9252032520325203,\n",
      " 'COLA:ends_with_question_mark/COLA_train/matthews_corr': 0.8260685528009882,\n",
      " 'COLA:ends_with_question_mark/COLA_valid/accuracy': 0.7543859649122807,\n",
      " 'COLA:ends_with_question_mark/COLA_valid/matthews_corr': 0.4742657956547625,\n",
      " 'model/None/glue': 0.5856531698367675}\n",
      "Cleaning checkpoints\n",
      "Writing metrics to /dfs/scratch0/vschen/metal-mmtl/logs/2019_03_17/20_39_08/metrics.json\n",
      "Writing log to /dfs/scratch0/vschen/metal-mmtl/logs/2019_03_17/20_39_08/log.json\n",
      "Full model saved at /dfs/scratch0/vschen/metal-mmtl/logs/2019_03_17/20_39_08/model.pkl\n"
     ]
    }
   ],
   "source": [
    "trainer.train_model(\n",
    "    model,\n",
    "    payloads_slice,\n",
    "    checkpoint_metric=\"COLA:ends_with_question_mark/COLA_valid/matthews_corr\",\n",
    "    checkpoint_metric_mode=\"max\",\n",
    "    checkoint_best=True,\n",
    "    writer=\"tensorboard\",\n",
    "    optimizer=\"adamax\",\n",
    "    lr=3e-5,\n",
    "    l2=1e-3,\n",
    "    log_every=0.05, \n",
    "    score_every=0.1,\n",
    "    n_epochs=1,\n",
    "    progress_bar=True,\n",
    "    checkpoint_tasks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Did we improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 57 / 1043 active labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'COLA/COLA_valid/accuracy': 0.8370086289549377,\n",
       " 'COLA/COLA_valid/matthews_corr': 0.6007221525351318,\n",
       " 'COLA:ends_with_question_mark/COLA_valid/accuracy': 0.7543859649122807,\n",
       " 'COLA:ends_with_question_mark/COLA_valid/matthews_corr': 0.4742657956547625}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metal.mmtl.metal_model import MetalModel\n",
    "model.score(payloads_slice[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# unfrozen, fine-tune only on COLA:questions\n",
    "{'COLA:ends_with_question_mark/COLA_valid/accuracy': 0.7017543859649122,\n",
    " 'COLA:ends_with_question_mark/COLA_valid/matthews_corr': 0.3656772505598269}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
