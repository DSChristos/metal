{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "def make_dataloader(n):\n",
    "    X = np.random.random((n, 2)) * 2 - 1\n",
    "    Y = (X[:, 0] > X[:, 1] + 0.25).astype(int) + 1\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "    div1 = int(n*0.8)\n",
    "    div2 = int(n*0.9)\n",
    "    Xs = [X[:div1], X[div1:div2], X[div2:]]\n",
    "    Ys = [Y[:div1], Y[div1:div2], Y[div2:]]\n",
    "\n",
    "    dataset = TensorDataset(Xs[0], Ys[0])\n",
    "    data_loader = DataLoader(dataset, batch_size=4)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'type' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-232765568dd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"foo_task\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfoo_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfoo_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoo_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoo_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SST-2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mbaz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CoLA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/mccreery/repos/metal/metal/mmtl/BERT_tasks.py\u001b[0m in \u001b[0;36mcreate_task\u001b[0;34m(task_name)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SST-2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSST2Dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertBinaryHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/mccreery/repos/metal/metal/mmtl/utils/dataset_utils.py\u001b[0m in \u001b[0;36mget_all_dataloaders\u001b[0;34m(dataset_name, bert_model, train_dev_split_prop, max_len, dl_kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m ):\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"\"\" Initializes train/dev/test dataloaders given dataset_class\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdataset_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# split train -> artificial train/dev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'type' and 'str'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from metal.mmtl.task import Task\n",
    "from BERT_tasks import create_task\n",
    "\n",
    "foo_input = nn.Linear(2, 10)\n",
    "bar_input = foo_input #nn.Linear(100, 7)\n",
    "\n",
    "foo_head = nn.Linear(10, 2)\n",
    "bar_head = nn.Linear(10, 2)\n",
    "\n",
    "foo_data = make_dataloader(5000)\n",
    "bar_data = make_dataloader(2000)\n",
    "\n",
    "foo = Task(\"foo_task\", {\"train\":foo_data, \"valid\":foo_data, \"test\":None}, foo_input, foo_head, )\n",
    "bar = create_task('SST-2')\n",
    "baz = create_task('CoLA')\n",
    "tasks = [foo,baz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from metal.end_model import EndModel\n",
    "from metal.mmtl.metal_model import MetalModel\n",
    "from metal.mmtl.trainer import MultitaskTrainer\n",
    "\n",
    "tasks = [bar]\n",
    "model = MetalModel(tasks, verbose=False)\n",
    "trainer = MultitaskTrainer()\n",
    "trainer.train_model(\n",
    "    model, \n",
    "    tasks, \n",
    "    n_epochs=3, \n",
    "    lr=0.005, \n",
    "    progress_bar=True,\n",
    "    log_every=1,\n",
    "    score_every=2,\n",
    "    checkpoint_best=True,\n",
    "    checkpoint_metric=\"SST-2/valid/accuracy\",\n",
    "    checkpoint_metric_mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
