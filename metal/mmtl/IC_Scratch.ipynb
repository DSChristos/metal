{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from metal import EndModel\n",
    "from preprocess import NlpProcess\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: run standard MeTaL (single-task) EndModel for QNLI ranking task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(data.Dataset):\n",
    "    def __init__(self, src_path, tokenizer):\n",
    "        super(BertDataset, self).__init__()\n",
    "        self.src_path = src_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.raw_data = None\n",
    "        self.tokens = None\n",
    "        self.segments = None\n",
    "        self.labels = None\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.tokens[index], self.segments[index]), self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.raw_data.shape[0]\n",
    "\n",
    "    def load_data(self):\n",
    "        self.raw_data = pd.read_csv(\n",
    "            self.src_path, sep='\\t', header=0,\n",
    "            index_col=0, error_bad_lines=False, warn_bad_lines=False\n",
    "        )\n",
    "        if 'label' not in self.raw_data.columns:\n",
    "            # add dummy column to match data input format\n",
    "            self.raw_data['label'] = ['entailment'] * self.__len__()\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        raise NotImplementedError\n",
    "            \n",
    "class QNLIDataset(BertDataset):\n",
    "    def __init__(self, src_path, tokenizer):\n",
    "        super(QNLIDataset, self).__init__(src_path, tokenizer)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        tokens_indices = []\n",
    "        segments = []\n",
    "        #for i, row in tqdm(data.iterrows()):\n",
    "        for i, row in tqdm(list(self.raw_data.iterrows())[:1]):\n",
    "            question = row.question\n",
    "            sentence = row.sentence\n",
    "            tokenized_question = self.tokenizer.tokenize(question)\n",
    "            tokenized_sentence = self.tokenizer.tokenize(sentence)\n",
    "            tokenized_text = tokenized_question + ['[SEP]'] + tokenized_sentence\n",
    "            tokens_indices.append(self.tokenizer.convert_tokens_to_ids(tokenized_text))\n",
    "            segments.append(([0] * (len(tokenized_question)+1)) + ([1] * len(tokenized_sentence)))\n",
    "            y_train[i, 0] = 1*(self.raw_data.label[i]=='entailment')\n",
    "            y_train[i, 1] = 1*(self.raw_data.label[i]=='not_entailment')\n",
    "        self.labels = labels\n",
    "        self.tokens = tokens_indices\n",
    "        self.segments = segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, max_len=-1):\n",
    "    batch_size = len(batch)\n",
    "    max_sent_len = int(np.max([len(x) for x in batch]))\n",
    "    if max_len > 0 and max_len < max_sent_len:\n",
    "        max_sent_len = max_len\n",
    "    if type == \"float\":\n",
    "        idx_matrix = np.zeros((batch_size, max_sent_len), dtype=np.float32)\n",
    "        seg_matrix = np.zeros((batch_size, max_sent_len), dtype=np.float32)\n",
    "        \n",
    "    else:\n",
    "        idx_matrix = np.zeros((batch_size, max_sent_len), dtype=np.int)\n",
    "        seg_matrix = np.zeros((batch_size, max_sent_len), dtype=np.float32)\n",
    "\n",
    "    for idx1 in np.arange(len(batch)):\n",
    "        (tokens, segments), labels = batch[idx1]\n",
    "        for idx2 in np.arange(len(tokens)):\n",
    "            if idx2 >= max_sent_len:\n",
    "                break\n",
    "            idx_matrix[idx1, idx2] = tokens[idx2]\n",
    "            seg_matrix[idx1, idx2] = segments[idx2]\n",
    "            \n",
    "    idx_matrix = torch.LongTensor(idx_matrix)\n",
    "    seg_matrix = torch.LongTensor(seg_matrix)\n",
    "    mask_matrix = torch.LongTensor(torch.eq(idx_matrix.data, -1))\n",
    "    return idx_matrix, seg_matrix, mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 188.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 458.49it/s]\n"
     ]
    }
   ],
   "source": [
    "model = 'bert-base-uncased' # also try bert-base-multilingual-cased (recommended)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "src_path = os.path.join(os.environ['METALHOME'], 'data/QNLI/{}.tsv')\n",
    "dataset = {}\n",
    "dataloaders = {}\n",
    "for split in ['train', 'test', 'dev']:\n",
    "    dataset[split] = QNLIDataset(src_path.format(split), tokenizer)\n",
    "    dataset[split].load_data()\n",
    "    dataset[split].preprocess_data()\n",
    "    dataloaders[split] = data.DataLoader(dataset[split], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What came into force after the new constitutio...</td>\n",
       "      <td>As of that day, the new constitution heralding...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the first major city in the stream of ...</td>\n",
       "      <td>The most important tributaries in this area ar...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the minimum required if you want to te...</td>\n",
       "      <td>In most provinces a second Bachelor's Degree s...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How was Temüjin kept imprisoned by the Tayichi...</td>\n",
       "      <td>The Tayichi'ud enslaved Temüjin (reportedly wi...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What did Herr Gott, dich loben wir become know...</td>\n",
       "      <td>He paraphrased the Te Deum as \"Herr Gott, dich...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "index                                                      \n",
       "0      What came into force after the new constitutio...   \n",
       "1      What is the first major city in the stream of ...   \n",
       "2      What is the minimum required if you want to te...   \n",
       "3      How was Temüjin kept imprisoned by the Tayichi...   \n",
       "4      What did Herr Gott, dich loben wir become know...   \n",
       "\n",
       "                                                sentence           label  \n",
       "index                                                                     \n",
       "0      As of that day, the new constitution heralding...      entailment  \n",
       "1      The most important tributaries in this area ar...  not_entailment  \n",
       "2      In most provinces a second Bachelor's Degree s...  not_entailment  \n",
       "3      The Tayichi'ud enslaved Temüjin (reportedly wi...      entailment  \n",
       "4      He paraphrased the Te Deum as \"Herr Gott, dich...  not_entailment  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['dev'].raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metal Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertEncoder, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "    def forward(self, tokens, segments):\n",
    "        # TODO: check if we should return all layers or just last hidden representation \n",
    "        _, hidden_layer = self.bert_model(tokens_tensors, segments_tensors)\n",
    "        return hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_module = BertEncoder()\n",
    "end_model = EndModel(\n",
    "    [768, 2],\n",
    "    input_module=encoder_module,\n",
    "    seed=123,\n",
    "    use_cuda=False,\n",
    "    skip_head=False,\n",
    "    input_relu=False,\n",
    "    input_batchnorm=False,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_model.train_model(dataloaders['train'],\n",
    "                      lr=0.01, l2=0.01, \n",
    "                      batch_size=256, \n",
    "                      n_epochs=5, checkpoint_metric='accuracy',\n",
    "                      checkpoint_metric_mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test end model\n",
    "end_model.score(test_loader, metric=[\"accuracy\", \"precision\", \"recall\", \"f1\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
