{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import metal\n",
    "import os\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import BERTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8551/8551 [00:02<00:00, 4033.24it/s]\n",
      "100%|██████████| 1043/1043 [00:00<00:00, 4146.40it/s]\n"
     ]
    }
   ],
   "source": [
    "model = 'bert-base-uncased' # also try bert-base-multilingual-cased (recommended)\n",
    "src_path = os.path.join(os.environ['GLUEDATA'], 'CoLA/{}.tsv')\n",
    "dataloaders = {}\n",
    "for split in ['train','dev']:\n",
    "    dataset = BERTDataset(\n",
    "        dataset_name = 'CoLA',\n",
    "        dataset_split = split,\n",
    "        sent1_idx=3,\n",
    "        label_idx=1,\n",
    "        skip_rows=0,\n",
    "        label_fn=lambda x: int(x)+1 # labels are scores [1, 2] (multiclass with cardinality k)\n",
    "    )\n",
    "\n",
    "    dataloaders[split] = dataset.get_dataloader(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from metal.end_model import EndModel\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertEncoder, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def forward(self, data):\n",
    "        tokens, segments, mask = data\n",
    "        # TODO: check if we should return all layers or just last hidden representation \n",
    "        _, hidden_layer = self.bert_model(tokens, segments, mask)\n",
    "        return hidden_layer\n",
    "\n",
    "class SSTHead(EndModel):     \n",
    "    def __init__(self, output_dims, **kwargs):\n",
    "        super(SSTHead, self).__init__(output_dims, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_module = BertEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_model = SSTHead(\n",
    "    [768, 2],\n",
    "    input_module=encoder_module,\n",
    "    seed=123,\n",
    "    skip_head=False,\n",
    "    input_relu=False,\n",
    "    input_batchnorm=False,\n",
    "    verbose=False,\n",
    "    device=torch.device(\"cuda\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.utils import place_on_gpu\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "def cola_metrics(model, dataloader):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    for batch in dataloader:\n",
    "        \n",
    "        # HACK -- we won't need to do this moving forward\n",
    "        batch = place_on_gpu(batch)\n",
    "        \n",
    "        data, Y = batch\n",
    "        \n",
    "        Y = Y.detach().cpu().numpy() - 1\n",
    "\n",
    "        output = model.forward(data)\n",
    "        prediction = output.detach().cpu().numpy()\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "        targets.append(Y)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    targets = np.concatenate(targets)    \n",
    "    predictions = np.concatenate(predictions)\n",
    "    metrics = {\n",
    "        \"matthews_corr\": matthews_corr(targets, predictions)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def matthews_corr(targets, predictions):\n",
    "    predictions = np.argmax(predictions,1)\n",
    "    return matthews_corrcoef(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU...\n",
      "Saving model at iteration 1 with best score 0.581\n",
      "Saving model at iteration 3 with best score 0.572\n",
      "[50 bat (0.02 epo)]: TRAIN:[loss=0.627, matthews_corr=0.232]\n",
      "[100 bat (0.04 epo)]: TRAIN:[loss=0.604, matthews_corr=0.412] VALID:[matthews_corr=0.313]\n",
      "Saving model at iteration 105 with best score 0.551\n",
      "Saving model at iteration 106 with best score 0.534\n",
      "Saving model at iteration 121 with best score 0.534\n",
      "[150 bat (0.05 epo)]: TRAIN:[loss=0.556, matthews_corr=0.432]\n",
      "Saving model at iteration 163 with best score 0.530\n",
      "Saving model at iteration 183 with best score 0.528\n",
      "Saving model at iteration 184 with best score 0.528\n",
      "Saving model at iteration 185 with best score 0.521\n",
      "Saving model at iteration 187 with best score 0.518\n",
      "Saving model at iteration 191 with best score 0.516\n",
      "Saving model at iteration 192 with best score 0.511\n",
      "Saving model at iteration 193 with best score 0.508\n",
      "Saving model at iteration 195 with best score 0.504\n",
      "Saving model at iteration 196 with best score 0.501\n",
      "Saving model at iteration 197 with best score 0.496\n",
      "[200 bat (0.07 epo)]: TRAIN:[loss=0.507, matthews_corr=0.364] VALID:[matthews_corr=0.249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/local/0/mccreery/repos/anaconda3/envs/metal/lib/python3.6/site-packages/sklearn/metrics/classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250 bat (0.09 epo)]: TRAIN:[loss=0.597, matthews_corr=0.000]\n",
      "Saving model at iteration 251 with best score 0.459\n",
      "Restoring best model from iteration 251 with score 0.459\n",
      "Finished Training\n",
      "Accuracy: 0.691\n",
      "        y=1    y=2   \n",
      " l=1     0     322   \n",
      " l=2     0     721   \n",
      "CPU times: user 1min 57s, sys: 50.5 s, total: 2min 47s\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "end_model.train_model(dataloaders['train'], valid_data=dataloaders['dev'],\n",
    "                      lr=0.0001, l2=0,\n",
    "                      n_epochs=1,\n",
    "                      log_train_metrics_func=[cola_metrics],\n",
    "                      log_train_metrics=[\"matthews_corr\"],\n",
    "                      log_train_every=50,\n",
    "                      log_valid_metrics_func=[cola_metrics],\n",
    "                      log_valid_metrics=[\"matthews_corr\"],\n",
    "                      log_valid_every=100,\n",
    "                      checkpoint_metric=\"train/loss\",#'spearman_corr',\n",
    "                      log_unit=\"batches\",\n",
    "                      checkpoint_metric_mode='min',\n",
    "                      verbose=True, progress_bar=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_metrics(end_model, dataloaders['dev'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
