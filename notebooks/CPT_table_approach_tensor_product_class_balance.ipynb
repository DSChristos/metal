{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate the true class balance to be recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27229227, 0.30204649, 0.02238635, 0.13577854, 0.26749635])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "\n",
    "# Generate the true class balance to be recovered\n",
    "p_Y = np.random.random(K)\n",
    "p_Y /= p_Y.sum()\n",
    "p_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate the true conditional probability tables (CPTs) for the LFs\n",
    "\n",
    "Separate simple process here to keep simple (later merge this with the SPA generator).\n",
    "Generate in terms of the _conditional accuracies_ (which is equivalent to the recall...):\n",
    "$$\n",
    "\\alpha_{i,y',y} = P(\\lambda_i = y' | Y = y)\n",
    "$$\n",
    "\n",
    "Note that this table should be normalized such that:\n",
    "$$\n",
    "\\sum_{y'} \\alpha_{i,y',y} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07319756, 0.02651444, 0.09248776, 0.04260887, 0.23961709],\n",
       "       [0.26413011, 0.26523537, 0.32580072, 0.13382714, 0.16266584],\n",
       "       [0.4914127 , 0.31934363, 0.3653866 , 0.25301543, 0.26904373],\n",
       "       [0.12198711, 0.30777312, 0.10216684, 0.2963796 , 0.11455197],\n",
       "       [0.04927252, 0.08113344, 0.11415808, 0.27416897, 0.21412137]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = 25\n",
    "alphas = []\n",
    "for i in range(M):\n",
    "    a = np.random.random((K,K))\n",
    "    alphas.append( a @ np.diag(1 / a.sum(axis=0)) )\n",
    "alpha = np.array(alphas)\n",
    "\n",
    "assert np.all(np.abs(alpha.sum(axis=1) - 1) < 1e-5)\n",
    "alpha[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate the _three-way_ overlaps tensor $O$ of conditionally-independent LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can directly generate $O$.\n",
    "By our conditional independence assumption, we have:\n",
    "$$\n",
    "P(\\lambda_i = y', \\lambda_j = y'' | Y = y) = \\alpha_{i,y',y} \\alpha_{j,y'',y}\n",
    "$$\n",
    "\n",
    "Thus we have:\n",
    "$$\n",
    "O_{i,j,y',y''} = \\sum_y P(Y=y) \\alpha_{i,y',y} \\alpha_{j,y'',y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mask\n",
    "mask = torch.ones((M,M,M,K,K,K)).byte()\n",
    "for i, j, k in product(range(M), repeat=3):\n",
    "    if len(set((i,j,k))) < 3:\n",
    "        mask[i,j,k,:,:,:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 365 ms, sys: 20.5 ms, total: 386 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "O = np.einsum('aby,cdy,efy,y->acebdf', alpha, alpha, alpha, p_Y)\n",
    "O = torch.from_numpy(O).float()\n",
    "O[1-mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute observed labeling rates\n",
    "O_l = torch.from_numpy(np.einsum('aby,y->ab', alpha, p_Y)).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Try to recover $O_\\Omega = \\left[ Q \\otimes Q \\otimes Q \\right]_\\Omega$\n",
    "\n",
    "Where $\\Omega$ is all the non-masked entries, and $Q = A P^{\\frac13}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(Q, O):\n",
    "    \n",
    "    # Main constraint: match empirical three-way overlaps matrix (entries O_ijk for i != j != k)\n",
    "    loss_1 = torch.norm((O - torch.einsum('aby,cdy,efy->acebdf', [Q,Q,Q]))[mask])**2\n",
    "    \n",
    "    # Col-wise stochastic: \\sum_y' P(\\lf=y'|Y=y) = 1.0\n",
    "    # loss_2 = torch.norm(torch.sum(A, 1) - 1)**2\n",
    "    \n",
    "    # Row-wise constraint: match observed labeling rates P(\\lf=y') = \\sum_y P(Y=y) P(\\lf=y'|Y=y)\n",
    "    # loss_3 = torch.norm(O_l - torch.einsum('aby,y->ab', [A,P]))**2\n",
    "    \n",
    "    # Pairwise observed: match empirical pairwise overlaps matrix (entries O_ij for i != j)\n",
    "    # loss_4 = torch.norm((O_2 - torch.einsum('aby,cdy,y->acbd', [A,A,P]))[mask_2])**2\n",
    "    \n",
    "    # return loss_1 + loss_2 + loss_3 # + loss_4\n",
    "    return loss_1\n",
    "\n",
    "def train_model_lbfgs(Q, O, n_epochs=10, lr=1, print_every=1):\n",
    "    optimizer = optim.LBFGS([Q], lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):        \n",
    "        def closure():\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to calculate outputs\n",
    "            loss = get_loss(Q, O)\n",
    "\n",
    "            # Backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Report progress\n",
    "            if epoch % print_every == 0:\n",
    "                msg = f\"[E:{epoch}]\\tLoss: {loss.detach():.8f}\"\n",
    "                print(msg)\n",
    "            \n",
    "            return loss\n",
    "\n",
    "        # Perform optimizer step\n",
    "        optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:0]\tLoss: 899771.75000000\n",
      "[E:0]\tLoss: 882881.81250000\n",
      "[E:0]\tLoss: 240359.60937500\n",
      "[E:0]\tLoss: 112120.60156250\n",
      "[E:0]\tLoss: 42985.32031250\n",
      "[E:0]\tLoss: 17680.87500000\n",
      "[E:0]\tLoss: 6948.71923828\n",
      "[E:0]\tLoss: 2704.19873047\n",
      "[E:0]\tLoss: 1026.13830566\n",
      "[E:0]\tLoss: 386.93591309\n",
      "[E:0]\tLoss: 149.85525513\n",
      "[E:0]\tLoss: 62.92713547\n",
      "[E:0]\tLoss: 28.17135620\n",
      "[E:0]\tLoss: 12.22554111\n",
      "[E:0]\tLoss: 6.93255424\n",
      "[E:0]\tLoss: 5.35690165\n",
      "[E:0]\tLoss: 4.30577278\n",
      "[E:0]\tLoss: 3.88412380\n",
      "[E:0]\tLoss: 3.05224180\n",
      "[E:0]\tLoss: 3.87679529\n",
      "[E:5]\tLoss: 0.00611107\n",
      "[E:5]\tLoss: 0.00607124\n",
      "[E:5]\tLoss: 0.00602758\n",
      "[E:5]\tLoss: 0.00597767\n",
      "[E:5]\tLoss: 0.00592760\n",
      "[E:5]\tLoss: 0.00586420\n",
      "[E:5]\tLoss: 0.00579483\n",
      "[E:5]\tLoss: 0.00574548\n",
      "[E:5]\tLoss: 0.00572724\n",
      "[E:5]\tLoss: 0.00569788\n",
      "[E:5]\tLoss: 0.00567550\n",
      "[E:5]\tLoss: 0.00561180\n",
      "[E:5]\tLoss: 0.00554335\n",
      "[E:5]\tLoss: 0.00541598\n",
      "[E:5]\tLoss: 0.00536661\n",
      "[E:5]\tLoss: 0.00508872\n",
      "[E:5]\tLoss: 0.00497434\n",
      "[E:5]\tLoss: 0.00479429\n",
      "[E:5]\tLoss: 0.00456464\n",
      "[E:5]\tLoss: 0.00467708\n",
      "[E:10]\tLoss: 0.00001572\n",
      "[E:10]\tLoss: 0.00001209\n",
      "[E:10]\tLoss: 0.00000966\n",
      "[E:10]\tLoss: 0.00000787\n",
      "[E:10]\tLoss: 0.00000689\n",
      "[E:10]\tLoss: 0.00000562\n",
      "[E:10]\tLoss: 0.00000498\n",
      "[E:10]\tLoss: 0.00000385\n",
      "[E:10]\tLoss: 0.00000288\n",
      "[E:10]\tLoss: 0.00000207\n",
      "[E:10]\tLoss: 0.00000163\n",
      "[E:10]\tLoss: 0.00000126\n",
      "[E:10]\tLoss: 0.00000098\n",
      "[E:10]\tLoss: 0.00000066\n",
      "[E:10]\tLoss: 0.00000042\n",
      "[E:10]\tLoss: 0.00000029\n",
      "[E:10]\tLoss: 0.00000018\n",
      "[E:10]\tLoss: 0.00000012\n",
      "[E:10]\tLoss: 0.00000009\n",
      "[E:10]\tLoss: 0.00000007\n"
     ]
    }
   ],
   "source": [
    "Q = nn.Parameter(torch.from_numpy(np.random.rand(M, K, K)).float()).float()\n",
    "train_model_lbfgs(Q, O, n_epochs=15, print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27229227, 0.30204649, 0.02238635, 0.13577854, 0.26749635])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1358, 0.3020, 0.2723, 0.2675, 0.0224], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_Y_est = Q[3].sum(0) ** 3\n",
    "p_Y_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_Y_est.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MeTaL)",
   "language": "python",
   "name": "metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
