{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate the true class balance to be recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65640301, 0.34359699])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 2\n",
    "\n",
    "# Generate the true class balance to be recovered\n",
    "p_Y = np.random.random(K)\n",
    "p_Y /= p_Y.sum()\n",
    "p_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate the true conditional probability tables (CPTs) for the LFs\n",
    "\n",
    "Separate simple process here to keep simple (later merge this with the SPA generator).\n",
    "Generate in terms of the _conditional accuracies_ (which is equivalent to the recall...):\n",
    "$$\n",
    "\\alpha_{i,y',y} = P(\\lambda_i = y' | Y = y)\n",
    "$$\n",
    "\n",
    "Note that this table should be normalized such that:\n",
    "$$\n",
    "\\sum_{y'} \\alpha_{i,y',y} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60167121, 0.28668221],\n",
       "       [0.39832879, 0.71331779]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = 25\n",
    "alphas = []\n",
    "for i in range(M):\n",
    "    a = np.random.random((K,K))\n",
    "    alphas.append( a @ np.diag(1 / a.sum(axis=0)) )\n",
    "alpha = np.array(alphas)\n",
    "\n",
    "assert np.all(np.abs(alpha.sum(axis=1) - 1) < 1e-5)\n",
    "alpha[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Different tensor product approaches in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.63 ms, sys: 258 µs, total: 7.88 ms\n",
      "Wall time: 7.93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "O_1 = np.zeros((M,M,K,K))\n",
    "for i, j, y1, y2 in product(range(M), range(M), range(K), range(K)):\n",
    "    for y in range(K):\n",
    "        O_1[i,j,y1,y2] += alpha[i, y1, y] * alpha[j, y2, y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) `np.tensordot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 714 µs, sys: 361 µs, total: 1.07 ms\n",
      "Wall time: 658 µs\n"
     ]
    }
   ],
   "source": [
    "%time O_2 = np.swapaxes(np.tensordot(alpha, alpha, axes=(2,2)), 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2656542480726785e-17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(O_1 - O_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) `np.einsum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 259 µs, sys: 120 µs, total: 379 µs\n",
      "Wall time: 326 µs\n"
     ]
    }
   ],
   "source": [
    "%time O_3 = np.einsum('iay,jby->ijab', alpha, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(O_1 - O_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, trying a bilinear form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 ms, sys: 284 µs, total: 9.04 ms\n",
      "Wall time: 9.17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Op_1 = np.zeros((M,M,K,K))\n",
    "for i, j, y1, y2 in product(range(M), range(M), range(K), range(K)):\n",
    "    for y in range(K):\n",
    "        Op_1[i,j,y1,y2] += p_Y[y] * alpha[i, y1, y] * alpha[j, y2, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 411 µs, sys: 56 µs, total: 467 µs\n",
      "Wall time: 420 µs\n"
     ]
    }
   ],
   "source": [
    "%time Op_3 = np.einsum('aby,y,cdy->acbd', alpha, p_Y, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.083433674002436e-18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(Op_1 - Op_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate the pairwise overlaps tensor $O$ of conditionally-independent LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can directly generate $O$.\n",
    "By our conditional independence assumption, we have:\n",
    "$$\n",
    "P(\\lambda_i = y', \\lambda_j = y'' | Y = y) = \\alpha_{i,y',y} \\alpha_{j,y'',y}\n",
    "$$\n",
    "\n",
    "Thus we have:\n",
    "$$\n",
    "O_{i,j,y',y''} = \\sum_y P(Y=y) \\alpha_{i,y',y} \\alpha_{j,y'',y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 550 µs, sys: 125 µs, total: 675 µs\n",
      "Wall time: 578 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "O = np.einsum('aby,y,cdy->acbd', alpha, p_Y, alpha)\n",
    "for i in range(M):\n",
    "    O[i,i,:,:] = 0.0\n",
    "O = torch.from_numpy(O).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.from_numpy(alpha).float()\n",
    "P = torch.from_numpy(p_Y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.6265e-13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones((M,M,K,K)).byte()\n",
    "for i in range(M):\n",
    "    mask[i,i,:,:] = 0\n",
    "\n",
    "torch.norm((O - torch.einsum('aby,y,cdy->acbd', [A,P,A]))[mask])**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Try to recover $\\alpha$ given $P(Y=y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones((M,M,K,K)).byte()\n",
    "for i in range(M):\n",
    "    mask[i,i,:,:] = 0\n",
    "\n",
    "def get_loss(A, P, O):\n",
    "    loss_1 = torch.norm((O - torch.einsum('aby,y,cdy->acbd', [A,P,A]))[mask])**2\n",
    "    loss_2 = torch.norm(torch.sum(A, 1) - 1)**2\n",
    "    return loss_1 + loss_2\n",
    "\n",
    "# Train the model\n",
    "def train_model(A, P, O, n_epochs=10, lr=0.01, print_every=1):\n",
    "    optimizer = optim.SGD([A], lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to calculate outputs\n",
    "        loss = get_loss(A, P, O)\n",
    "\n",
    "        # Backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Keep running sum of losses\n",
    "        epoch_loss += loss.detach()\n",
    "\n",
    "        # Report progress\n",
    "        if epoch % print_every == 0:\n",
    "            msg = f\"[E:{epoch}]\\tLoss: {epoch_loss:.8f}\"\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E:0]\tLoss: 118.10226440\n",
      "[E:100]\tLoss: 0.58557749\n",
      "[E:200]\tLoss: 0.00237393\n",
      "[E:300]\tLoss: 0.00002269\n",
      "[E:400]\tLoss: 0.00000034\n",
      "Param estimation error: 6.0834185818131605e-06\n"
     ]
    }
   ],
   "source": [
    "A = nn.Parameter(torch.from_numpy(np.random.rand(M, K, K)).float()).float()\n",
    "P = torch.from_numpy(p_Y).float()\n",
    "\n",
    "train_model(A, P, O, n_epochs=500, lr=0.01, print_every=100)\n",
    "\n",
    "print(f\"Param estimation error: {np.mean(np.abs(A.detach().numpy() - alpha))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6017, 0.2867],\n",
       "        [0.3983, 0.7133]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60167121, 0.28668221],\n",
       "       [0.39832879, 0.71331779]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MeTaL)",
   "language": "python",
   "name": "metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
